# SPDX-FileCopyrightText: 2025 Stanford University, ETH Zurich, and the project authors
# SPDX-License-Identifier: MIT

"""
PromptBank å’Œ PrototypeBank

å¤šæ•°æ®é›†ç»Ÿä¸€è®­ç»ƒçš„æ ¸å¿ƒç»„ä»¶ï¼š
- PromptBank: æ¯æ•°æ®é›†çš„å¯å­¦ä¹ Prompt Tokens
- PrototypeBank: æ¯æ•°æ®é›†çš„PrototypeçŸ©é˜µ + å¯å­¦ä¹ æ¸©åº¦
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Dict, Optional


class PromptBank(nn.Module):
    """
    å¯å­¦ä¹  Prompt Token Bank
    
    æ¯ä¸ªæ•°æ®é›†æœ‰ç‹¬ç«‹çš„ prompt embeddingsã€‚
    
    å‚æ•°å½¢çŠ¶: [num_datasets, prompt_len, hidden_size]
    
    Args:
        num_datasets: æ•°æ®é›†æ€»æ•°
        prompt_len: æ¯ä¸ªæ•°æ®é›†çš„prompté•¿åº¦
        hidden_size: LLMéšå±‚ç»´åº¦
        init_mean: ç”¨äºåˆå§‹åŒ–çš„å‡å€¼å‘é‡ (å¯é€‰)
        init_std: ç”¨äºåˆå§‹åŒ–çš„æ ‡å‡†å·®å‘é‡ (å¯é€‰)
        dtype: æ•°æ®ç±»å‹
    """
    
    def __init__(
        self,
        num_datasets: int,
        prompt_len: int,
        hidden_size: int,
        init_mean: Optional[torch.Tensor] = None,
        init_std: Optional[torch.Tensor] = None,
        dtype: torch.dtype = torch.bfloat16,
        device: str = "cuda",
    ):
        super().__init__()
        self.num_datasets = num_datasets
        self.prompt_len = prompt_len
        self.hidden_size = hidden_size
        
        # åˆå§‹åŒ– prompt embeddings
        if init_mean is not None and init_std is not None:
            # ä½¿ç”¨LLM embeddingç»Ÿè®¡ä¿¡æ¯åˆå§‹åŒ–
            # [num_datasets, prompt_len, hidden_size]
            prompt_init = init_mean.view(1, 1, -1).expand(num_datasets, prompt_len, -1).clone()
            noise = torch.randn(num_datasets, prompt_len, hidden_size, device=device, dtype=dtype)
            # å¢å¤§æ‰°åŠ¨ç³»æ•°: 0.1 -> 0.5
            prompt_init = prompt_init + noise * init_std.view(1, 1, -1) * 0.5
            self.prompts = nn.Parameter(prompt_init)
        else:
            # éšæœºåˆå§‹åŒ–
            self.prompts = nn.Parameter(
                torch.randn(num_datasets, prompt_len, hidden_size, device=device, dtype=dtype) * 0.02
            )
        
        print(f"ğŸ“ PromptBank: {num_datasets} datasets Ã— {prompt_len} tokens Ã— {hidden_size} dim")
    
    def get(self, ds_id: int) -> torch.Tensor:
        """
        è·å–æŒ‡å®šæ•°æ®é›†çš„prompt embeddings
        
        Args:
            ds_id: æ•°æ®é›†ID
            
        Returns:
            [prompt_len, hidden_size]
        """
        return self.prompts[ds_id]
    
    def get_batch(self, ds_ids: torch.Tensor) -> torch.Tensor:
        """
        è·å–ä¸€æ‰¹æ•°æ®é›†çš„prompt embeddings
        
        Args:
            ds_ids: [B] æ•°æ®é›†IDå¼ é‡
            
        Returns:
            [B, prompt_len, hidden_size]
        """
        return self.prompts[ds_ids]


class PrototypeBankEntry(nn.Module):
    """
    å•ä¸ªæ•°æ®é›†çš„Prototype + æ¸©åº¦
    
    åŒ…å«ï¼š
    - prototypes: [num_classes, hidden_size]
    - log_temperature: å¯å­¦ä¹ æ¸©åº¦ï¼ˆlogç©ºé—´ï¼‰
    """
    
    def __init__(
        self,
        num_classes: int,
        hidden_size: int,
        init_temperature: float = 1.0,
        init_mean: Optional[torch.Tensor] = None,
        init_std: Optional[torch.Tensor] = None,
        dtype: torch.dtype = torch.bfloat16,
        device: str = "cuda",
    ):
        super().__init__()
        self.num_classes = num_classes
        self.hidden_size = hidden_size
        
        # PrototypeçŸ©é˜µ
        if init_mean is not None and init_std is not None:
            # ä½¿ç”¨LLM embeddingç»Ÿè®¡ä¿¡æ¯åˆå§‹åŒ–
            # [num_classes, hidden_size]
            proto_init = init_mean.unsqueeze(0).expand(num_classes, -1).clone()
            noise = torch.randn(num_classes, hidden_size, device=device, dtype=dtype)
            
            # å¢å¤§æ‰°åŠ¨ç³»æ•°: 0.1 -> 1.0ï¼Œç¡®ä¿prototypeä¹‹é—´æœ‰è¶³å¤Ÿçš„åŒºåˆ†åº¦
            # å¯¹äºå¤šç±»åˆ«æ•°æ®é›†ï¼Œå¦‚æœprototypeå¤ªæ¥è¿‘ï¼Œä¼šå¯¼è‡´å¾ˆéš¾è®­ç»ƒ
            proto_init = proto_init + noise * init_std * 1.0
            self.prototypes = nn.Parameter(proto_init)
        else:
            # éšæœºæ­£äº¤åˆå§‹åŒ– (å¦‚æœç±»åˆ«æ•° <= hidden_size)
            if num_classes <= hidden_size:
                # æ­£äº¤åˆå§‹åŒ–èƒ½æœ€å¤§åŒ–åˆå§‹åŒºåˆ†åº¦
                weight = torch.empty(num_classes, hidden_size, device=device, dtype=dtype)
                nn.init.orthogonal_(weight)
                self.prototypes = nn.Parameter(weight * 0.1)  # ç¼©æ”¾ä»¥åŒ¹é…é€šå¸¸çš„embeddingèŒƒæ•°
            else:
                self.prototypes = nn.Parameter(
                    torch.randn(num_classes, hidden_size, device=device, dtype=dtype) * 0.02
                )
        
        # å¯å­¦ä¹ æ¸©åº¦ï¼ˆlogç©ºé—´ç¡®ä¿ä¸ºæ­£ï¼‰
        self.log_temperature = nn.Parameter(
            torch.log(torch.tensor(init_temperature, dtype=torch.float32, device=device))
        )
    
    @property
    def temperature(self) -> torch.Tensor:
        """è¿”å›æ¸©åº¦å€¼"""
        return self.log_temperature.exp().clamp(min=0.01, max=100.0)
    
    def forward(self, z: torch.Tensor) -> torch.Tensor:
        """
        è®¡ç®—logits
        
        Args:
            z: [B, hidden_size] CLSéšå‘é‡
            
        Returns:
            [B, num_classes] logits
        """
        # L2å½’ä¸€åŒ–
        z_norm = F.normalize(z, p=2, dim=-1)
        proto_norm = F.normalize(self.prototypes, p=2, dim=-1)
        
        # ä½™å¼¦ç›¸ä¼¼åº¦
        similarity = torch.matmul(z_norm, proto_norm.T)  # [B, num_classes]
        
        # æ¸©åº¦ç¼©æ”¾
        logits = similarity / self.temperature
        
        return logits


class PrototypeBank(nn.Module):
    """
    PrototypeçŸ©é˜µ + æ¸©åº¦ Bank
    
    æ¯ä¸ªæ•°æ®é›†æœ‰ç‹¬ç«‹çš„ï¼š
    - P_i: [C_i, hidden_size] prototypeçŸ©é˜µ
    - Ï„_i: å¯å­¦ä¹ æ¸©åº¦æ ‡é‡
    
    Args:
        class_counts: {ds_id: num_classes} æ¯ä¸ªæ•°æ®é›†çš„ç±»åˆ«æ•°
        hidden_size: LLMéšå±‚ç»´åº¦
        init_temperature: æ¸©åº¦åˆå§‹å€¼
        init_mean: ç”¨äºåˆå§‹åŒ–çš„å‡å€¼å‘é‡ (å¯é€‰)
        init_std: ç”¨äºåˆå§‹åŒ–çš„æ ‡å‡†å·®å‘é‡ (å¯é€‰)
        dtype: æ•°æ®ç±»å‹
    """
    
    def __init__(
        self,
        class_counts: Dict[int, int],
        hidden_size: int,
        init_temperature: float = 1.0,
        init_mean: Optional[torch.Tensor] = None,
        init_std: Optional[torch.Tensor] = None,
        dtype: torch.dtype = torch.bfloat16,
        device: str = "cuda",
    ):
        super().__init__()
        self.hidden_size = hidden_size
        self.class_counts = class_counts
        
        # ä¸ºæ¯ä¸ªæ•°æ®é›†åˆ›å»º PrototypeBankEntry
        self.entries = nn.ModuleDict()
        for ds_id, num_classes in class_counts.items():
            self.entries[str(ds_id)] = PrototypeBankEntry(
                num_classes=num_classes,
                hidden_size=hidden_size,
                init_temperature=init_temperature,
                init_mean=init_mean,
                init_std=init_std,
                dtype=dtype,
                device=device,
            )
        
        print(f"ğŸ¯ PrototypeBank: {len(class_counts)} datasets")
        for ds_id, num_classes in class_counts.items():
            print(f"   [{ds_id}]: {num_classes} classes")
    
    def logits(self, ds_id: int, z_cls: torch.Tensor) -> torch.Tensor:
        """
        è®¡ç®—æŒ‡å®šæ•°æ®é›†çš„åˆ†ç±»logits
        
        Args:
            ds_id: æ•°æ®é›†ID
            z_cls: [B, hidden_size] CLSéšå‘é‡
            
        Returns:
            [B, num_classes] logits
        """
        return self.entries[str(ds_id)](z_cls)
    
    def get_temperature(self, ds_id: int) -> float:
        """è·å–æŒ‡å®šæ•°æ®é›†çš„æ¸©åº¦å€¼"""
        return self.entries[str(ds_id)].temperature.item()
    
    def get_prototypes(self, ds_id: int) -> torch.Tensor:
        """è·å–æŒ‡å®šæ•°æ®é›†çš„prototypeçŸ©é˜µ"""
        return self.entries[str(ds_id)].prototypes
    
    def get_num_classes(self, ds_id: int) -> int:
        """è·å–æŒ‡å®šæ•°æ®é›†çš„ç±»åˆ«æ•°"""
        return self.class_counts[ds_id]


# æµ‹è¯•
if __name__ == "__main__":
    print("Testing PromptBank and PrototypeBank...")
    
    device = "cuda" if torch.cuda.is_available() else "cpu"
    
    # æµ‹è¯• PromptBank
    prompt_bank = PromptBank(
        num_datasets=3,
        prompt_len=10,
        hidden_size=256,
        device=device,
    )
    
    prompt_0 = prompt_bank.get(0)
    print(f"Prompt 0 shape: {prompt_0.shape}")  # [10, 256]
    
    ds_ids = torch.tensor([0, 1, 2], device=device)
    prompts = prompt_bank.get_batch(ds_ids)
    print(f"Batch prompts shape: {prompts.shape}")  # [3, 10, 256]
    
    # æµ‹è¯• PrototypeBank
    class_counts = {0: 2, 1: 5, 2: 10}
    proto_bank = PrototypeBank(
        class_counts=class_counts,
        hidden_size=256,
        device=device,
    )
    
    z = torch.randn(4, 256, device=device, dtype=torch.bfloat16)
    logits_0 = proto_bank.logits(0, z)
    logits_1 = proto_bank.logits(1, z)
    print(f"Logits for ds_id=0: {logits_0.shape}")  # [4, 2]
    print(f"Logits for ds_id=1: {logits_1.shape}")  # [4, 5]
    
    print(f"Temperature for ds_id=0: {proto_bank.get_temperature(0):.4f}")
    
    print("\nâœ… All tests passed!")
