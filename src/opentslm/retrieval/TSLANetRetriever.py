# SPDX-FileCopyrightText: 2025 Stanford University, ETH Zurich, and the project authors (see CONTRIBUTORS.md)
# SPDX-FileCopyrightText: 2025 This source file is part of the OpenTSLM open-source project.
#
# SPDX-License-Identifier: MIT

"""
TSLANetæ£€ç´¢å™¨

åŸºäºTSLANetçš„ç›¸ä¼¼æ ·æœ¬æ£€ç´¢å™¨ï¼Œç”¨äºICLåˆ†ç±»çš„æ”¯æŒæ ·æœ¬æ£€ç´¢ã€‚

ç‰¹æ€§ï¼š
- æŒ‰ç±»åˆ«åˆ†ç»„å»ºç´¢å¼•ï¼šä¸ºæ¯ä¸ªç±»åˆ«å•ç‹¬å­˜å‚¨æ ·æœ¬ç´¢å¼•
- æŒ‰ç±»åˆ«æ£€ç´¢ï¼šå¯¹æ¯ä¸ªç±»åˆ«æ£€ç´¢top-mæœ€è¿‘é‚»ï¼Œé€‰å–k_shotä¸ª
- Queryæ’é™¤ï¼šè®­ç»ƒæ—¶è‡ªåŠ¨æ’é™¤queryè‡ªèº«

ä½¿ç”¨æµç¨‹ï¼š
1. åŠ è½½è®­ç»ƒå¥½çš„TSLANet encoder
2. å¯¹è®­ç»ƒé›†æ„å»ºç´¢å¼• (build_index)
3. å¯¹æ¯ä¸ªqueryæ£€ç´¢æ”¯æŒæ ·æœ¬ (retrieve)
"""

import os
import torch
import torch.nn.functional as F
import numpy as np
from typing import Dict, List, Tuple, Optional, Union
from tqdm.auto import tqdm


class TSLANetRetriever:
    """
    åŸºäºTSLANetçš„ç›¸ä¼¼æ ·æœ¬æ£€ç´¢å™¨
    
    æ”¯æŒæŒ‰ç±»åˆ«åˆ†ç»„çš„æ£€ç´¢ç­–ç•¥ï¼š
    - ç¦»çº¿æ„å»ºæŒ‰ç±»åˆ«åˆ†ç»„çš„ç´¢å¼•
    - å¯¹æ¯ä¸ªç±»åˆ«å•ç‹¬æ£€ç´¢top-mæœ€è¿‘é‚»
    - ä»top-mä¸­é€‰å–k_shotä¸ªä½œä¸ºæ”¯æŒæ ·æœ¬
    
    Args:
        encoder: TSLANetEncoderå®ä¾‹ (éœ€è¦æœ‰get_embeddingæ–¹æ³•)
        device: è®¡ç®—è®¾å¤‡
    """
    
    def __init__(
        self,
        encoder,  # TSLANetEncoder or TSLANetClassifier
        device: str = "cuda"
    ):
        self.encoder = encoder
        self.device = device
        
        # ç´¢å¼•æ•°æ®
        self.embeddings: Optional[torch.Tensor] = None  # [N, emb_dim]
        self.labels: Optional[torch.Tensor] = None  # [N]
        self.time_series: Optional[torch.Tensor] = None  # [N, L]
        self.class_indices: Dict[int, List[int]] = {}  # ç±»åˆ« -> æ ·æœ¬ç´¢å¼•åˆ—è¡¨
        self.num_classes: int = 0
        
        # ç¡®ä¿encoderåœ¨æ­£ç¡®è®¾å¤‡ä¸Š
        self.encoder = self.encoder.to(device)
        self.encoder.eval()
    
    @torch.no_grad()
    def build_index(
        self,
        time_series: torch.Tensor,
        labels: torch.Tensor,
        batch_size: int = 64,
        show_progress: bool = True
    ):
        """
        ç¦»çº¿æ„å»ºæŒ‰ç±»åˆ«åˆ†ç»„çš„ç´¢å¼•
        
        Args:
            time_series: [N, L] æ‰€æœ‰è®­ç»ƒæ ·æœ¬çš„æ—¶é—´åºåˆ—
            labels: [N] å¯¹åº”çš„æ ‡ç­¾ (0-indexed)
            batch_size: è®¡ç®—embeddingæ—¶çš„æ‰¹æ¬¡å¤§å°
            show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦æ¡
        """
        N = time_series.shape[0]
        
        # å­˜å‚¨åŸå§‹æ•°æ®
        self.time_series = time_series.cpu()
        self.labels = labels.cpu()
        
        # è®¡ç®—æ‰€æœ‰embedding
        all_embeddings = []
        
        iterator = range(0, N, batch_size)
        if show_progress:
            iterator = tqdm(iterator, desc="Building index")
        
        for i in iterator:
            batch = time_series[i:i+batch_size].to(self.device)
            
            # è·å–embedding
            if hasattr(self.encoder, 'get_embedding'):
                emb = self.encoder.get_embedding(batch)
            else:
                # å¦‚æœæ²¡æœ‰get_embeddingæ–¹æ³•ï¼Œä½¿ç”¨forwardåå¹³å‡æ± åŒ–
                features = self.encoder(batch)  # [B, N_patches, dim]
                emb = features.mean(dim=1)  # [B, dim]
            
            all_embeddings.append(emb.cpu())
        
        self.embeddings = torch.cat(all_embeddings, dim=0)  # [N, emb_dim]
        
        # L2å½’ä¸€åŒ–ç”¨äºä½™å¼¦ç›¸ä¼¼åº¦
        self.embeddings = F.normalize(self.embeddings, p=2, dim=-1)
        
        # æŒ‰ç±»åˆ«åˆ†ç»„å»ºç´¢å¼•
        self.class_indices = {}
        unique_labels = torch.unique(self.labels).tolist()
        self.num_classes = len(unique_labels)
        
        for cls in unique_labels:
            mask = (self.labels == cls)
            indices = torch.where(mask)[0].tolist()
            self.class_indices[cls] = indices
        
        print(f"âœ… ç´¢å¼•æ„å»ºå®Œæˆ: {N} æ ·æœ¬, {self.num_classes} ç±»åˆ«")
        for cls, indices in self.class_indices.items():
            print(f"   ç±»åˆ« {cls}: {len(indices)} æ ·æœ¬")
    
    @torch.no_grad()
    def retrieve(
        self,
        query_emb: torch.Tensor,
        query_idx: Optional[int] = None,
        k_shot: int = 1,
        top_m: int = 10,
        exclude_query: bool = True,
        target_labels: Optional[List[int]] = None
    ) -> Tuple[List[int], List[torch.Tensor], List[int]]:
        """
        æŒ‰ç±»åˆ«æ£€ç´¢æ”¯æŒæ ·æœ¬
        
        å¯¹æ¯ä¸ªç±»åˆ«ï¼š
        1. è®¡ç®—queryä¸è¯¥ç±»æ‰€æœ‰æ ·æœ¬çš„ç›¸ä¼¼åº¦
        2. å–top-mæœ€ç›¸ä¼¼çš„æ ·æœ¬
        3. ä»top-mä¸­é€‰å–å‰k_shotä¸ªï¼ˆæ’é™¤queryè‡ªèº«ï¼‰
        
        Args:
            query_emb: [emb_dim] queryçš„embedding (å·²å½’ä¸€åŒ–)
            query_idx: queryåœ¨ç´¢å¼•ä¸­çš„å…¨å±€ç´¢å¼• (ç”¨äºæ’é™¤è‡ªèº«)
            k_shot: æ¯ä¸ªç±»åˆ«é€‰å–çš„æ”¯æŒæ ·æœ¬æ•°
            top_m: æ¯ä¸ªç±»åˆ«æ£€ç´¢çš„å€™é€‰æ•°é‡
            exclude_query: æ˜¯å¦æ’é™¤queryè‡ªèº«
            target_labels: ç›®æ ‡ç±»åˆ«åˆ—è¡¨ (åªä»è¿™äº›ç±»åˆ«ä¸­æ£€ç´¢, Noneè¡¨ç¤ºæ£€ç´¢æ‰€æœ‰ç±»åˆ«)
        
        Returns:
            support_indices: æ”¯æŒæ ·æœ¬çš„å…¨å±€ç´¢å¼•åˆ—è¡¨
            support_ts: æ”¯æŒæ ·æœ¬çš„æ—¶é—´åºåˆ—åˆ—è¡¨
            support_labels: æ”¯æŒæ ·æœ¬çš„æ ‡ç­¾åˆ—è¡¨
        """
        if self.embeddings is None:
            raise RuntimeError("è¯·å…ˆè°ƒç”¨ build_index() æ„å»ºç´¢å¼•")
        
        # ç¡®å®šquery_embå½’ä¸€åŒ–
        query_emb = F.normalize(query_emb.cpu().unsqueeze(0), p=2, dim=-1).squeeze(0)
        
        support_indices = []
        support_ts = []
        support_labels = []
        
        # ç¡®å®šè¦æ£€ç´¢çš„ç±»åˆ«
        if target_labels is not None:
            classes_to_search = [cls for cls in target_labels if cls in self.class_indices]
        else:
            classes_to_search = sorted(self.class_indices.keys())
        
        # å¯¹æ¯ä¸ªç±»åˆ«æ£€ç´¢
        for cls in classes_to_search:
            cls_global_indices = self.class_indices[cls]
            
            if len(cls_global_indices) == 0:
                continue
            
            # è·å–è¯¥ç±»åˆ«æ‰€æœ‰æ ·æœ¬çš„embedding
            cls_embs = self.embeddings[cls_global_indices]  # [N_cls, emb_dim]
            
            # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦ (ç”±äºå·²å½’ä¸€åŒ–ï¼Œç‚¹ç§¯=ä½™å¼¦ç›¸ä¼¼åº¦)
            similarities = torch.matmul(cls_embs, query_emb)  # [N_cls]
            
            # æ’åºå–top-m
            sorted_local_indices = similarities.argsort(descending=True)
            
            # é€‰å–k_shotä¸ªï¼ˆæ’é™¤queryè‡ªèº«ï¼‰
            count = 0
            for local_idx in sorted_local_indices:
                if count >= k_shot:
                    break
                
                global_idx = cls_global_indices[local_idx.item()]
                
                # æ’é™¤queryè‡ªèº«
                if exclude_query and query_idx is not None and global_idx == query_idx:
                    continue
                
                support_indices.append(global_idx)
                support_ts.append(self.time_series[global_idx])
                support_labels.append(cls)
                count += 1
                
                # å·²è¾¾åˆ°top_mé™åˆ¶ (ä½†ä¼˜å…ˆä¿è¯k_shot)
                if local_idx.item() >= top_m - 1 and count < k_shot:
                    # å¦‚æœåœ¨top_må†…è¿˜æ²¡å‡‘å¤Ÿk_shotï¼Œç»§ç»­æ‰¾
                    pass
        
        return support_indices, support_ts, support_labels
    
    @torch.no_grad()
    def retrieve_for_query(
        self,
        query_ts: torch.Tensor,
        query_idx: Optional[int] = None,
        k_shot: int = 1,
        top_m: int = 10,
        exclude_query: bool = True,
        target_labels: Optional[List[int]] = None
    ) -> Tuple[List[int], List[torch.Tensor], List[int]]:
        """
        ç»™å®šqueryæ—¶é—´åºåˆ—ï¼Œæ£€ç´¢æ”¯æŒæ ·æœ¬
        
        Args:
            query_ts: [L] queryæ—¶é—´åºåˆ—
            query_idx: queryåœ¨ç´¢å¼•ä¸­çš„å…¨å±€ç´¢å¼•
            k_shot: æ¯ä¸ªç±»åˆ«é€‰å–çš„æ”¯æŒæ ·æœ¬æ•°
            top_m: æ¯ä¸ªç±»åˆ«æ£€ç´¢çš„å€™é€‰æ•°é‡
            exclude_query: æ˜¯å¦æ’é™¤queryè‡ªèº«
            target_labels: ç›®æ ‡ç±»åˆ«åˆ—è¡¨ (åªä»è¿™äº›ç±»åˆ«ä¸­æ£€ç´¢, Noneè¡¨ç¤ºæ£€ç´¢æ‰€æœ‰ç±»åˆ«)
        
        Returns:
            åŒ retrieve()
        """
        # è®¡ç®—queryçš„embedding
        query_ts = query_ts.unsqueeze(0).to(self.device)  # [1, L]
        
        if hasattr(self.encoder, 'get_embedding'):
            query_emb = self.encoder.get_embedding(query_ts)  # [1, emb_dim]
        else:
            features = self.encoder(query_ts)
            query_emb = features.mean(dim=1)
        
        query_emb = query_emb.squeeze(0).cpu()  # [emb_dim]
        
        return self.retrieve(query_emb, query_idx, k_shot, top_m, exclude_query, target_labels)
    
    def save_index(self, path: str):
        """ä¿å­˜ç´¢å¼•åˆ°æ–‡ä»¶"""
        torch.save({
            "embeddings": self.embeddings,
            "labels": self.labels,
            "time_series": self.time_series,
            "class_indices": self.class_indices,
            "num_classes": self.num_classes
        }, path)
        print(f"ğŸ’¾ ç´¢å¼•å·²ä¿å­˜åˆ°: {path}")
    
    def load_index(self, path: str):
        """ä»æ–‡ä»¶åŠ è½½ç´¢å¼•"""
        data = torch.load(path, map_location="cpu", weights_only=False)
        self.embeddings = data["embeddings"]
        self.labels = data["labels"]
        self.time_series = data["time_series"]
        self.class_indices = data["class_indices"]
        self.num_classes = data["num_classes"]
        print(f"ğŸ“‚ ç´¢å¼•å·²åŠ è½½: {len(self.labels)} æ ·æœ¬, {self.num_classes} ç±»åˆ«")
    
    def get_class_distribution(self) -> Dict[int, int]:
        """è·å–ç±»åˆ«åˆ†å¸ƒ"""
        return {cls: len(indices) for cls, indices in self.class_indices.items()}


# --- æµ‹è¯•ä»£ç  ---
if __name__ == "__main__":
    print("Testing TSLANetRetriever...")
    
    # æ¨¡æ‹Ÿä¸€ä¸ªç®€å•çš„encoder
    class MockEncoder:
        def __init__(self, emb_dim=128):
            self.emb_dim = emb_dim
        
        def to(self, device):
            return self
        
        def eval(self):
            pass
        
        def get_embedding(self, x):
            # éšæœºè¿”å›embedding
            B = x.shape[0]
            return torch.randn(B, self.emb_dim)
    
    # åˆ›å»ºæ£€ç´¢å™¨
    encoder = MockEncoder()
    retriever = TSLANetRetriever(encoder, device="cpu")
    
    # æ„å»ºç´¢å¼•
    N, L = 100, 50
    time_series = torch.randn(N, L)
    labels = torch.randint(0, 5, (N,))  # 5ä¸ªç±»åˆ«
    
    retriever.build_index(time_series, labels, batch_size=32)
    
    # æµ‹è¯•æ£€ç´¢
    query_ts = torch.randn(L)
    indices, ts_list, label_list = retriever.retrieve_for_query(
        query_ts, query_idx=None, k_shot=2, top_m=10
    )
    
    print(f"æ£€ç´¢åˆ° {len(indices)} ä¸ªæ”¯æŒæ ·æœ¬")
    print(f"æ ‡ç­¾åˆ†å¸ƒ: {sorted(label_list)}")
    
    # æµ‹è¯•ä¿å­˜/åŠ è½½
    retriever.save_index("test_index.pt")
    retriever.load_index("test_index.pt")
    os.remove("test_index.pt")
    
    print("âœ… æµ‹è¯•é€šè¿‡!")
