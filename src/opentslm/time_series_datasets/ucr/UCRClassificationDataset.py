# SPDX-FileCopyrightText: 2025 Stanford University, ETH Zurich, and the project authors (see CONTRIBUTORS.md)
# SPDX-FileCopyrightText: 2025 This source file is part of the OpenTSLM open-source project.
#
# SPDX-License-Identifier: MIT

"""
UCRå•æ•°æ®é›†åˆ†ç±»Dataset

ç”¨äºM1å®éªŒï¼šéªŒè¯æ—¶åº-LLMé€šè·¯çš„æœ‰ç›‘ç£åˆ†ç±»èƒ½åŠ›ã€‚
ä½¿ç”¨LLaVAèŒƒå¼ï¼ˆSoft Promptï¼‰è¿›è¡ŒæŒ‡ä»¤å¼åˆ†ç±»ã€‚
æ ‡ç­¾æ˜ å°„ä¸ºç‰¹æ®Štokenæ ¼å¼: <c0>, <c1>, ...
"""

import os
import string
from typing import List, Tuple, Literal, Optional
import pandas as pd
import torch

from opentslm.prompt.text_time_series_prompt import TextTimeSeriesPrompt
from opentslm.time_series_datasets.QADataset import QADataset
from opentslm.time_series_datasets.ucr.ucr_loader import load_ucr_dataset, ensure_ucr_data


def index_to_class_token(index: int) -> str:
    """
    å°†æ•´æ•°ç´¢å¼•è½¬æ¢ä¸ºç‰¹æ®Šç±»åˆ«tokenã€‚
    
    æ˜ å°„è§„åˆ™ï¼š
    0 -> <c0>
    1 -> <c1>
    ...
    K-1 -> <cK-1>
    
    Args:
        index: éè´Ÿæ•´æ•°ç´¢å¼• (ä»0å¼€å§‹)
    
    Returns:
        å¯¹åº”çš„ç‰¹æ®Šç±»åˆ«token
    
    Examples:
        >>> index_to_class_token(0)
        '<c0>'
        >>> index_to_class_token(5)
        '<c5>'
        >>> index_to_class_token(25)
        '<c25>'
    """
    if index < 0:
        raise ValueError(f"Index must be non-negative, got {index}")
    return f"<c{index}>"


class UCRClassificationDataset(QADataset):
    """
    UCRå•æ•°æ®é›†åˆ†ç±»Dataset
    
    Promptæ ¼å¼ï¼š
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    Classify the time series into one of {num_classes} classes.
    Output only the class token.

    Time series:
    <TS_TOKENS>
    
    Class:
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    Answer: <c0> (æˆ– <c1>, <c2>, ...)
    
    Args:
        dataset_name: UCRæ•°æ®é›†åç§° (e.g. "ECG5000")
        split: æ•°æ®åˆ’åˆ† ("train", "validation", "test")
        EOS_TOKEN: ç»“æŸtoken
        raw_data_path: æ•°æ®è·¯å¾„
        val_ratio: ä»è®­ç»ƒé›†åˆ’åˆ†éªŒè¯é›†çš„æ¯”ä¾‹ (UCRæ²¡æœ‰å®˜æ–¹éªŒè¯é›†)
    """
    
    # ç±»å˜é‡å­˜å‚¨æ•°æ®é›†ä¿¡æ¯
    _dataset_name: str = None
    _label_to_token: dict = None
    _token_to_label: dict = None
    _num_classes: int = None
    _class_tokens: List[str] = None
    
    def __init__(
        self,
        split: Literal["train", "test", "validation"],
        EOS_TOKEN: str,
        dataset_name: str = "ECG5000",
        raw_data_path: str = "./data",
        val_ratio: float = 0.1,
        format_sample_str: bool = False,
        time_series_format_function=None,
    ):
        # å­˜å‚¨å®ä¾‹å˜é‡
        self._instance_dataset_name = dataset_name
        self._instance_raw_data_path = raw_data_path
        self._instance_val_ratio = val_ratio
        
        # è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–
        super().__init__(split, EOS_TOKEN, format_sample_str, time_series_format_function)
    
    def _load_splits(self) -> Tuple[List, List, List]:
        """
        åŠ è½½UCRæ•°æ®é›†
        
        UCRåªæœ‰trainå’Œtestï¼Œç›´æ¥ä½¿ç”¨testä½œä¸ºvalidationï¼ˆä¸ä»è®­ç»ƒé›†åˆ’åˆ†ï¼‰
        """
        ensure_ucr_data()
        
        dataset_name = self._instance_dataset_name
        raw_data_path = self._instance_raw_data_path
        
        # åŠ è½½æ•°æ®
        train_df, test_df = load_ucr_dataset(dataset_name, raw_data_path=raw_data_path)
        
        # è·å–æ‰€æœ‰å”¯ä¸€æ ‡ç­¾å¹¶æ’åº
        all_labels = sorted(train_df["label"].unique().tolist())
        num_classes = len(all_labels)
        
        # åˆ›å»ºæ ‡ç­¾åˆ°ç‰¹æ®Štokençš„æ˜ å°„ (0-><c0>, 1-><c1>, ...)
        tokens = [index_to_class_token(i) for i in range(num_classes)]
        label_to_token = {label: tokens[i] for i, label in enumerate(all_labels)}
        token_to_label = {v: k for k, v in label_to_token.items()}
        
        # å­˜å‚¨ç±»å˜é‡
        UCRClassificationDataset._dataset_name = dataset_name
        UCRClassificationDataset._label_to_token = label_to_token
        UCRClassificationDataset._token_to_label = token_to_label
        UCRClassificationDataset._num_classes = num_classes
        UCRClassificationDataset._class_tokens = tokens
        
        print(f"ğŸ“Š Dataset: {dataset_name}")
        print(f"   Classes: {num_classes}")
        print(f"   Label mapping: {label_to_token}")
        print(f"   Train samples: {len(train_df)}")
        print(f"   Test samples: {len(test_df)}")
        print(f"   (Validation = Test)")
        
        # è½¬æ¢ä¸ºåˆ—è¡¨å½¢å¼
        train_list = train_df.to_dict('records')
        # validationå’Œtestä½¿ç”¨ç›¸åŒçš„æ•°æ®
        val_list = test_df.to_dict('records')
        test_list = test_df.to_dict('records')
        
        return train_list, val_list, test_list
    
    def _get_pre_prompt(self, row) -> str:
        """è¿”å›é¢„æç¤ºæ–‡æœ¬"""
        num_classes = UCRClassificationDataset._num_classes
        
        prompt = f"""Classify the time series into one of {num_classes} classes.
Output only the class token.

Time series data:"""
        return prompt
    
    def _get_post_prompt(self, row) -> str:
        """è¿”å›åæç¤ºæ–‡æœ¬"""
        return "\nClass:"
    
    def _get_answer(self, row) -> str:
        """è¿”å›ç­”æ¡ˆï¼ˆç‰¹æ®Šç±»åˆ«tokenï¼‰"""
        original_label = row["label"]
        class_token = UCRClassificationDataset._label_to_token[original_label]
        return class_token
    
    def _get_text_time_series_prompt_list(self, row) -> List[TextTimeSeriesPrompt]:
        """å°†æ—¶é—´åºåˆ—è½¬æ¢ä¸ºTextTimeSeriesPromptåˆ—è¡¨"""
        # æå–æ—¶é—´åºåˆ—æ•°æ® (é™¤äº†labelåˆ—çš„æ‰€æœ‰åˆ—)
        feature_cols = [col for col in row.keys() if col != "label"]
        values = [row[col] for col in feature_cols]
        
        # è½¬æ¢ä¸ºtensor
        tensor = torch.tensor(values, dtype=torch.float32)
        
        # å¤„ç†NaNå€¼
        tensor = torch.nan_to_num(tensor, nan=0.0)
        
        # Per-sample z-normalization
        mean = tensor.mean()
        std = tensor.std()
        if std > 1e-8:
            tensor = (tensor - mean) / std
        else:
            tensor = tensor - mean
        
        # åˆ›å»ºprompt (ç®€å•æè¿°)
        # text_prompt = f"This is a univariate time series with {len(tensor)} data points, mean={mean:.4f}, std={std:.4f}:"
        text_prompt = f"This is a univariate time series with {len(tensor)} data points:"
        
        return [TextTimeSeriesPrompt(text_prompt, tensor.tolist())]
    
    def _format_sample(self, row):
        """æ ¼å¼åŒ–æ ·æœ¬ï¼Œæ·»åŠ é¢å¤–ä¿¡æ¯"""
        sample = super()._format_sample(row)
        # ä¿å­˜åŸå§‹æ ‡ç­¾ç”¨äºè¯„ä¼°
        sample["original_label"] = row["label"]
        sample["class_token"] = UCRClassificationDataset._label_to_token[row["label"]]
        
        # æ·»åŠ æ•´æ•°æ ‡ç­¾ (0 åˆ° K-1)
        # ä» label_to_token æ˜ å°„ä¸­è·å–ç´¢å¼•
        all_labels = sorted(UCRClassificationDataset._label_to_token.keys())
        sample["int_label"] = all_labels.index(row["label"])
        
        return sample
    
    @staticmethod
    def get_class_tokens() -> List[str]:
        """è¿”å›æ‰€æœ‰ç±»åˆ«çš„ç‰¹æ®Štoken"""
        return UCRClassificationDataset._class_tokens or []
    
    @staticmethod
    def get_num_classes() -> int:
        """è¿”å›ç±»åˆ«æ•°é‡"""
        return UCRClassificationDataset._num_classes or 0
    
    @staticmethod
    def get_label_mapping() -> dict:
        """è¿”å›åŸå§‹æ ‡ç­¾åˆ°ç‰¹æ®Štokençš„æ˜ å°„"""
        return UCRClassificationDataset._label_to_token or {}
    
    @staticmethod
    def token_to_original(token: str) -> int:
        """å°†ç‰¹æ®Štokenè½¬æ¢å›åŸå§‹æ ‡ç­¾"""
        return UCRClassificationDataset._token_to_label.get(token, -1)


# æµ‹è¯•
if __name__ == "__main__":
    # æµ‹è¯•æ•°æ®é›†åŠ è½½
    print("Testing UCRClassificationDataset...")
    
    dataset = UCRClassificationDataset(
        split="train",
        EOS_TOKEN="<eos>",
        dataset_name="ECG200",
    )
    
    print(f"\nDataset size: {len(dataset)}")
    print(f"Class tokens: {UCRClassificationDataset.get_class_tokens()}")
    print(f"Label mapping: {UCRClassificationDataset.get_label_mapping()}")
    
    # æŸ¥çœ‹æ ·æœ¬
    if len(dataset) > 0:
        sample = dataset[0]
        print("\n" + "="*50)
        print("Sample keys:", sample.keys())
        print("Pre-prompt:", sample["pre_prompt"])
        print("Post-prompt:", sample["post_prompt"])
        print("Answer:", sample["answer"])
        print("Class token:", sample.get("class_token", "N/A"))
        print("Original label:", sample.get("original_label", "N/A"))
        print("Time series text:", sample.get("time_series_text", ["N/A"])[0][:100] + "...")
