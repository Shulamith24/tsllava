# SPDX-FileCopyrightText: 2025 Stanford University, ETH Zurich, and the project authors (see CONTRIBUTORS.md)
# SPDX-FileCopyrightText: 2025 This source file is part of the OpenTSLM open-source project.
#
# SPDX-License-Identifier: MIT

"""
UEAå¤šå˜é‡æ—¶é—´åºåˆ—åˆ†ç±»Dataset

ç”¨äºM1å®éªŒï¼šéªŒè¯æ—¶åº-LLMé€šè·¯çš„æœ‰ç›‘ç£åˆ†ç±»èƒ½åŠ›ã€‚
é‡‡ç”¨ä¸HAR/PAMAP2ç›¸åŒçš„å¤šé€šé“å¤„ç†æ–¹å¼ã€‚
"""

import string
from typing import List, Tuple, Literal
import numpy as np
import torch

from opentslm.prompt.text_time_series_prompt import TextTimeSeriesPrompt
from opentslm.time_series_datasets.QADataset import QADataset
from opentslm.time_series_datasets.uea.uea_loader import load_uea_dataset, ensure_uea_data


class UEAClassificationDataset(QADataset):
    """
    UEAå¤šå˜é‡æ—¶é—´åºåˆ—åˆ†ç±»Dataset
    
    é‡‡ç”¨ä¸HAR/PAMAP2ç›¸åŒçš„å¤šé€šé“å¤„ç†æ–¹å¼ï¼š
    - æ¯ä¸ªé€šé“åˆ›å»ºç‹¬ç«‹çš„TextTimeSeriesPrompt
    - æ¯ä¸ªé€šé“ç‹¬ç«‹z-normalization
    - æ ‡ç­¾æ˜ å°„ä¸ºA, B, C, ...
    
    Args:
        dataset_name: UEAæ•°æ®é›†åç§° (e.g. "Handwriting")
        split: æ•°æ®åˆ’åˆ† ("train", "validation", "test")
        EOS_TOKEN: ç»“æŸtoken
    """
    
    # ç±»å˜é‡å­˜å‚¨æ•°æ®é›†ä¿¡æ¯
    _dataset_name: str = None
    _label_to_letter: dict = None
    _letter_to_label: dict = None
    _num_classes: int = None
    _num_channels: int = None
    _class_letters: List[str] = None
    
    def __init__(
        self,
        split: Literal["train", "test", "validation"],
        EOS_TOKEN: str,
        dataset_name: str = "Handwriting",
        format_sample_str: bool = False,
        time_series_format_function=None,
    ):
        # å­˜å‚¨å®ä¾‹å˜é‡
        self._instance_dataset_name = dataset_name
        
        # è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–
        super().__init__(split, EOS_TOKEN, format_sample_str, time_series_format_function)
    
    def _load_splits(self) -> Tuple[List, List, List]:
        """
        åŠ è½½UEAæ•°æ®é›†
        
        UEAåªæœ‰trainå’Œtestï¼Œä½¿ç”¨testä½œä¸ºvalidation
        """
        ensure_uea_data()
        
        dataset_name = self._instance_dataset_name
        
        # åŠ è½½æ•°æ®
        X_train, y_train, X_test, y_test = load_uea_dataset(dataset_name)
        
        # è·å–æ‰€æœ‰å”¯ä¸€æ ‡ç­¾å¹¶æ’åº
        all_labels = sorted(np.unique(y_train).tolist())
        num_classes = len(all_labels)
        num_channels = X_train.shape[1]
        
        # åˆ›å»ºæ ‡ç­¾åˆ°å­—æ¯çš„æ˜ å°„
        letters = list(string.ascii_uppercase)[:num_classes]
        label_to_letter = {label: letters[i] for i, label in enumerate(all_labels)}
        letter_to_label = {v: k for k, v in label_to_letter.items()}
        
        # å­˜å‚¨ç±»å˜é‡
        UEAClassificationDataset._dataset_name = dataset_name
        UEAClassificationDataset._label_to_letter = label_to_letter
        UEAClassificationDataset._letter_to_label = letter_to_label
        UEAClassificationDataset._num_classes = num_classes
        UEAClassificationDataset._num_channels = num_channels
        UEAClassificationDataset._class_letters = letters
        
        print(f"ğŸ“Š Dataset: {dataset_name}")
        print(f"   Classes: {num_classes}")
        print(f"   Channels: {num_channels}")
        print(f"   Label mapping: {label_to_letter}")
        print(f"   Train samples: {len(X_train)}")
        print(f"   Test samples: {len(X_test)}")
        print(f"   (Validation = Test)")
        
        # è½¬æ¢ä¸ºåˆ—è¡¨å½¢å¼ï¼ˆæ¯ä¸ªæ ·æœ¬æ˜¯ä¸€ä¸ªdictï¼‰
        train_list = self._convert_to_list(X_train, y_train)
        # validationå’Œtestä½¿ç”¨ç›¸åŒçš„æ•°æ®
        val_list = self._convert_to_list(X_test, y_test)
        test_list = self._convert_to_list(X_test, y_test)
        
        return train_list, val_list, test_list
    
    def _convert_to_list(self, X: np.ndarray, y: np.ndarray) -> List[dict]:
        """å°†numpyæ•°ç»„è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨"""
        result = []
        for i in range(len(X)):
            result.append({
                "time_series": X[i],  # [C, L]
                "label": y[i],
            })
        return result
    
    def _get_pre_prompt(self, row) -> str:
        """è¿”å›é¢„æç¤ºæ–‡æœ¬"""
        dataset_name = UEAClassificationDataset._dataset_name
        num_classes = UEAClassificationDataset._num_classes
        num_channels = UEAClassificationDataset._num_channels
        class_letters = UEAClassificationDataset._class_letters
        
        classes_str = ", ".join(class_letters)
        
        prompt = f"""You are a multivariate time series classifier for the {dataset_name} dataset.
        This dataset contains {num_classes} classes: {classes_str}.
        The time series has {num_channels} channels.
        Analyze all channels and output ONLY the single letter label.

        Time series data:"""
        return prompt
    
    def _get_post_prompt(self, row) -> str:
        """è¿”å›åæç¤ºæ–‡æœ¬"""
        return "Label:"
    
    def _get_answer(self, row) -> str:
        """è¿”å›ç­”æ¡ˆï¼ˆå­—æ¯æ ‡ç­¾ï¼‰"""
        original_label = row["label"]
        letter_label = UEAClassificationDataset._label_to_letter[original_label]
        return letter_label
    
    def _get_text_time_series_prompt_list(self, row) -> List[TextTimeSeriesPrompt]:
        """
        å°†å¤šå˜é‡æ—¶é—´åºåˆ—è½¬æ¢ä¸ºTextTimeSeriesPromptåˆ—è¡¨
        
        é‡‡ç”¨ä¸HAR/PAMAP2ç›¸åŒçš„æ–¹å¼ï¼šæ¯ä¸ªé€šé“ç‹¬ç«‹å¤„ç†
        """
        # time_series: [C, L]
        series = row["time_series"]
        
        # è½¬æ¢ä¸ºtensor [C, L]
        if isinstance(series, np.ndarray):
            series = torch.tensor(series, dtype=torch.float32)
        
        # å¤„ç†NaNå€¼
        series = torch.nan_to_num(series, nan=0.0)
        
        num_channels = series.shape[0]
        
        # æ¯ä¸ªé€šé“ç‹¬ç«‹å½’ä¸€åŒ–
        means = series.mean(dim=1, keepdim=True)  # [C, 1]
        stds = series.std(dim=1, keepdim=True)    # [C, 1]
        
        # å¤„ç†é›¶æˆ–å¾ˆå°çš„æ ‡å‡†å·®
        min_std = 1e-6
        stds = torch.clamp(stds, min=min_std)
        
        series_norm = (series - means) / stds  # [C, L]
        
        # æ£€æŸ¥NaN/Inf
        if torch.isnan(series_norm).any() or torch.isinf(series_norm).any():
            print(f"âš ï¸ NaN/Inf detected after normalization, replacing with 0")
            series_norm = torch.nan_to_num(series_norm, nan=0.0, posinf=0.0, neginf=0.0)
        
        # åˆ›å»ºæ¯ä¸ªé€šé“çš„promptï¼ˆä¸HAR/PAMAP2ä¸€è‡´ï¼‰
        prompts = []
        for i in range(num_channels):
            channel_data = series_norm[i].tolist()
            mean_val = means[i].item()
            std_val = stds[i].item()
            
            # text_prompt = f"Channel {i+1} data (mean={mean_val:.4f}, std={std_val:.4f}):"
            text_prompt = f"Channel {i+1} data:"
            prompts.append(TextTimeSeriesPrompt(text_prompt, channel_data))
        
        return prompts
    
    def _format_sample(self, row):
        """æ ¼å¼åŒ–æ ·æœ¬ï¼Œæ·»åŠ é¢å¤–ä¿¡æ¯"""
        sample = super()._format_sample(row)
        # ä¿å­˜åŸå§‹æ ‡ç­¾ç”¨äºè¯„ä¼°
        sample["original_label"] = row["label"]
        sample["letter_label"] = UEAClassificationDataset._label_to_letter[row["label"]]
        return sample
    
    @staticmethod
    def get_labels() -> List[str]:
        """è¿”å›æ‰€æœ‰ç±»åˆ«çš„å­—æ¯æ ‡ç­¾"""
        return UEAClassificationDataset._class_letters or []
    
    @staticmethod
    def get_label_mapping() -> dict:
        """è¿”å›åŸå§‹æ ‡ç­¾åˆ°å­—æ¯çš„æ˜ å°„"""
        return UEAClassificationDataset._label_to_letter or {}


# æµ‹è¯•
if __name__ == "__main__":
    print("Testing UEAClassificationDataset...")
    
    dataset = UEAClassificationDataset(
        split="train",
        EOS_TOKEN="<eos>",
        dataset_name="AtrialFibrillation",
    )
    
    print(f"\nDataset size: {len(dataset)}")
    print(f"Labels: {UEAClassificationDataset.get_labels()}")
    print(f"Label mapping: {UEAClassificationDataset.get_label_mapping()}")
    
    # æŸ¥çœ‹æ ·æœ¬
    if len(dataset) > 0:
        sample = dataset[0]
        print("\n" + "="*50)
        print("Sample keys:", sample.keys())
        print("Pre-prompt:", sample["pre_prompt"])
        print("Post-prompt:", sample["post_prompt"])
        print("Answer:", sample["answer"])
        print("Letter label:", sample.get("letter_label", "N/A"))
        print("Num time series:", len(sample.get("time_series_text", [])))
            
