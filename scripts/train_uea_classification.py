#!/usr/bin/env python3
# SPDX-FileCopyrightText: 2025 Stanford University, ETH Zurich, and the project authors (see CONTRIBUTORS.md)
# SPDX-FileCopyrightText: 2025 This source file is part of the OpenTSLM open-source project.
#
# SPDX-License-Identifier: MIT

"""
M1: UEAå¤šå˜é‡æ•°æ®é›†åˆ†ç±»è®­ç»ƒ

éªŒè¯OpenTSLMSPæ¶æ„åœ¨UEAå¤šå˜é‡æ•°æ®é›†ä¸Šçš„æœ‰ç›‘ç£åˆ†ç±»èƒ½åŠ›ã€‚
ä½¿ç”¨LLaVAèŒƒå¼ï¼ˆSoft Promptï¼‰è¿›è¡ŒæŒ‡ä»¤å¼åˆ†ç±»ã€‚

ä½¿ç”¨æ–¹æ³•ï¼š
    python scripts/train_uea_classification.py \
        --dataset Epilepsy \
        --encoder_type tslanet \
        --epochs 30 \
        --batch_size 4 \
        --use_lora

è®­ç»ƒé…ç½®ï¼š
- LoRA: r=16, alpha=32 (å¯é€‰)
- Encoder LR: 2e-4
- Projector LR: 1e-4
- LoRA LR: 1e-4
"""

import os
import sys
import json
import argparse
import datetime
from pathlib import Path
from typing import List, Dict, Any

import torch
from torch.optim import AdamW
from torch.nn.utils import clip_grad_norm_
from torch.utils.data import DataLoader
from tqdm.auto import tqdm
from transformers import get_linear_schedule_with_warmup

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root / "src"))

from opentslm.model.llm.OpenTSLMSP import OpenTSLMSP
from opentslm.time_series_datasets.uea.UEAClassificationDataset import UEAClassificationDataset
from opentslm.time_series_datasets.util import extend_time_series_to_match_patch_size_and_aggregate
from opentslm.model_config import PATCH_SIZE


def parse_args():
    parser = argparse.ArgumentParser(description="M1: UEAå¤šå˜é‡æ•°æ®é›†åˆ†ç±»è®­ç»ƒ")
    
    # æ•°æ®ç›¸å…³
    parser.add_argument(
        "--dataset",
        type=str,
        default="Epilepsy",
        help="UEAæ•°æ®é›†åç§°",
    )
    
    # æ¨¡å‹ç›¸å…³
    parser.add_argument(
        "--encoder_type",
        type=str,
        default="tslanet",
        choices=["transformer_cnn", "tslanet"],
        help="ç¼–ç å™¨ç±»å‹",
    )
    parser.add_argument(
        "--encoder_pretrained",
        type=str,
        default=None,
        help="TSLANeté¢„è®­ç»ƒæƒé‡è·¯å¾„",
    )
    parser.add_argument(
        "--llm_id",
        type=str,
        default="meta-llama/Llama-3.2-1B",
        help="LLMæ¨¡å‹ID",
    )
    
    # LoRAç›¸å…³
    parser.add_argument("--use_lora", action="store_true", help="æ˜¯å¦ä½¿ç”¨LoRA")
    parser.add_argument("--lora_r", type=int, default=16, help="LoRA rank")
    parser.add_argument("--lora_alpha", type=int, default=32, help="LoRA alpha")
    
    # è®­ç»ƒç›¸å…³
    parser.add_argument("--epochs", type=int, default=30, help="è®­ç»ƒè½®æ•°")
    parser.add_argument("--batch_size", type=int, default=4, help="æ‰¹æ¬¡å¤§å°")
    parser.add_argument("--lr_encoder", type=float, default=2e-4, help="ç¼–ç å™¨å­¦ä¹ ç‡")
    parser.add_argument("--lr_projector", type=float, default=1e-4, help="æŠ•å½±å±‚å­¦ä¹ ç‡")
    parser.add_argument("--lr_lora", type=float, default=1e-4, help="LoRAå­¦ä¹ ç‡")
    parser.add_argument("--weight_decay", type=float, default=1e-2, help="æƒé‡è¡°å‡")
    parser.add_argument("--grad_clip", type=float, default=1.0, help="æ¢¯åº¦è£å‰ª")
    parser.add_argument("--warmup_ratio", type=float, default=0.03, help="é¢„çƒ­æ¯”ä¾‹")
    
    # ä¿å­˜ç›¸å…³
    parser.add_argument(
        "--save_dir",
        type=str,
        default="results/m1_uea_classification",
        help="ç»“æœä¿å­˜ç›®å½•",
    )
    
    # å…¶ä»–
    parser.add_argument("--seed", type=int, default=42, help="éšæœºç§å­")
    parser.add_argument("--device", type=str, default="cuda", help="è®¾å¤‡")
    parser.add_argument("--eval_every", type=int, default=5, help="æ¯Nè½®è¯„ä¼°ä¸€æ¬¡")
    parser.add_argument("--early_stop", type=int, default=10, help="æ—©åœè€å¿ƒå€¼")
    parser.add_argument("--max_new_tokens", type=int, default=10, help="ç”Ÿæˆæœ€å¤§tokenæ•°")
    
    return parser.parse_args()


def set_seed(seed: int):
    """è®¾ç½®éšæœºç§å­"""
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)


def calculate_accuracy(predictions: List[str], labels: List[str]) -> float:
    """è®¡ç®—åˆ†ç±»å‡†ç¡®ç‡"""
    correct = 0
    for pred, label in zip(predictions, labels):
        pred_clean = pred.strip()
        pred_label = None
        
        if len(pred_clean) == 1 and pred_clean.isalpha():
            pred_label = pred_clean.upper()
        elif pred_clean:
            words = pred_clean.split()
            if words:
                last_word = words[-1].strip(".,!?:;")
                if last_word and last_word[0].isalpha():
                    pred_label = last_word[0].upper()
        
        label_clean = label.strip().upper()
        if pred_label == label_clean:
            correct += 1
    
    return correct / len(predictions) if predictions else 0.0


def create_data_loaders(args, eos_token: str):
    """åˆ›å»ºæ•°æ®åŠ è½½å™¨"""
    train_dataset = UEAClassificationDataset(
        split="train",
        EOS_TOKEN=eos_token,
        dataset_name=args.dataset,
    )
    
    val_dataset = UEAClassificationDataset(
        split="validation",
        EOS_TOKEN=eos_token,
        dataset_name=args.dataset,
    )
    
    test_dataset = UEAClassificationDataset(
        split="test",
        EOS_TOKEN=eos_token,
        dataset_name=args.dataset,
    )
    
    def collate_fn(batch):
        return extend_time_series_to_match_patch_size_and_aggregate(
            batch, patch_size=PATCH_SIZE
        )
    
    train_loader = DataLoader(
        train_dataset,
        batch_size=args.batch_size,
        shuffle=True,
        collate_fn=collate_fn,
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=1,
        shuffle=False,
        collate_fn=collate_fn,
    )
    
    test_loader = DataLoader(
        test_dataset,
        batch_size=1,
        shuffle=False,
        collate_fn=collate_fn,
    )
    
    return train_loader, val_loader, test_loader


def train_one_epoch(
    model: OpenTSLMSP,
    train_loader: DataLoader,
    optimizer,
    scheduler,
    grad_clip: float,
    device: str,
    epoch: int,
    num_epochs: int,
) -> float:
    """è®­ç»ƒä¸€ä¸ªepoch"""
    model.train()
    total_loss = 0.0
    num_batches = 0
    
    pbar = tqdm(train_loader, desc=f"Epoch {epoch}/{num_epochs}")
    for batch in pbar:
        loss = model.compute_loss(batch)
        
        optimizer.zero_grad()
        loss.backward()
        clip_grad_norm_(model.parameters(), max_norm=grad_clip)
        optimizer.step()
        scheduler.step()
        
        total_loss += loss.item()
        num_batches += 1
        
        pbar.set_postfix({
            "loss": f"{loss.item():.4f}",
            "lr": f"{scheduler.get_last_lr()[0]:.2e}"
        })
    
    return total_loss / max(num_batches, 1)


@torch.no_grad()
def evaluate(
    model: OpenTSLMSP,
    data_loader: DataLoader,
    max_new_tokens: int,
    desc: str = "Evaluating",
) -> Dict[str, Any]:
    """è¯„ä¼°æ¨¡å‹"""
    model.eval()
    
    all_predictions = []
    all_labels = []
    total_loss = 0.0
    num_batches = 0
    
    for batch in tqdm(data_loader, desc=desc):
        loss = model.compute_loss(batch)
        total_loss += loss.item()
        num_batches += 1
        
        predictions = model.generate(batch, max_new_tokens=max_new_tokens)
        
        for sample, pred in zip(batch, predictions):
            all_predictions.append(pred)
            all_labels.append(sample["answer"].replace(model.get_eos_token(), "").strip())
    
    avg_loss = total_loss / max(num_batches, 1)
    accuracy = calculate_accuracy(all_predictions, all_labels)
    
    return {
        "loss": avg_loss,
        "accuracy": accuracy,
        "predictions": all_predictions,
        "labels": all_labels,
    }


def save_checkpoint(
    model: OpenTSLMSP,
    optimizer,
    scheduler,
    epoch: int,
    val_loss: float,
    val_acc: float,
    save_path: str,
    args,
):
    """ä¿å­˜checkpoint"""
    checkpoint = {
        "encoder_state": model.encoder.state_dict(),
        "projector_state": model.projector.state_dict(),
        "optimizer_state": optimizer.state_dict(),
        "scheduler_state": scheduler.state_dict(),
        "epoch": epoch,
        "val_loss": val_loss,
        "val_acc": val_acc,
        "args": vars(args),
    }
    
    model.save_lora_state_to_checkpoint(checkpoint)
    torch.save(checkpoint, save_path)
    print(f"ğŸ’¾ Saved checkpoint to: {save_path}")


def main():
    args = parse_args()
    
    print("=" * 60)
    print("M1: UEAå¤šå˜é‡æ•°æ®é›†åˆ†ç±»è®­ç»ƒ")
    print("=" * 60)
    print(f"æ—¶é—´: {datetime.datetime.now()}")
    print(f"æ•°æ®é›†: {args.dataset}")
    print(f"ç¼–ç å™¨: {args.encoder_type}")
    print(f"LoRA: {args.use_lora}")
    print("=" * 60)
    
    set_seed(args.seed)
    
    if args.device == "cuda" and not torch.cuda.is_available():
        print("âš ï¸ CUDAä¸å¯ç”¨ï¼Œä½¿ç”¨CPU")
        args.device = "cpu"
    device = args.device
    
    save_dir = os.path.join(args.save_dir, args.dataset)
    os.makedirs(save_dir, exist_ok=True)
    
    with open(os.path.join(save_dir, "config.json"), "w") as f:
        json.dump(vars(args), f, indent=2)
    
    print("\nğŸ”§ åˆ›å»ºæ¨¡å‹...")
    tslanet_config = {"patch_size": 4}
    
    model = OpenTSLMSP(
        llm_id=args.llm_id,
        device=device,
        encoder_type=args.encoder_type,
        encoder_pretrained_path=args.encoder_pretrained,
        tslanet_config=tslanet_config if args.encoder_type == "tslanet" else None,
    )
    
    if args.use_lora:
        print("ğŸ“ å¯ç”¨LoRA...")
        model.enable_lora(lora_r=args.lora_r, lora_alpha=args.lora_alpha)
    
    print("\nğŸ“‚ åŠ è½½æ•°æ®...")
    eos_token = model.get_eos_token()
    train_loader, val_loader, test_loader = create_data_loaders(args, eos_token)
    
    print(f"   Train batches: {len(train_loader)}")
    print(f"   Val batches: {len(val_loader)}")
    print(f"   Test batches: {len(test_loader)}")
    
    print("\nâš™ï¸ åˆ›å»ºä¼˜åŒ–å™¨...")
    param_groups = [
        {"params": model.encoder.parameters(), "lr": args.lr_encoder},
        {"params": model.projector.parameters(), "lr": args.lr_projector},
    ]
    
    if args.use_lora:
        lora_params = model.get_lora_parameters()
        if lora_params:
            param_groups.append({"params": lora_params, "lr": args.lr_lora})
    
    optimizer = AdamW(param_groups, weight_decay=args.weight_decay)
    
    total_steps = args.epochs * len(train_loader)
    warmup_steps = int(args.warmup_ratio * total_steps)
    scheduler = get_linear_schedule_with_warmup(
        optimizer,
        num_warmup_steps=warmup_steps,
        num_training_steps=total_steps,
    )
    
    print(f"   Total steps: {total_steps}")
    print(f"   Warmup steps: {warmup_steps}")
    
    print("\nğŸš€ å¼€å§‹è®­ç»ƒ...")
    best_val_acc = 0.0
    patience_counter = 0
    loss_history = []
    
    for epoch in range(1, args.epochs + 1):
        train_loss = train_one_epoch(
            model, train_loader, optimizer, scheduler,
            args.grad_clip, device, epoch, args.epochs
        )
        
        if epoch % args.eval_every == 0 or epoch == args.epochs:
            print(f"\nğŸ“Š Epoch {epoch} è¯„ä¼°...")
            
            val_results = evaluate(model, val_loader, args.max_new_tokens, "Validating")
            val_loss = val_results["loss"]
            val_acc = val_results["accuracy"]
            
            print(f"   Train Loss: {train_loss:.4f}")
            print(f"   Val Loss: {val_loss:.4f}")
            print(f"   Val Accuracy: {val_acc:.4f}")
            
            print("   Sample predictions:")
            for i in range(min(3, len(val_results["predictions"]))):
                pred = val_results["predictions"][i]
                label = val_results["labels"][i]
                pred_short = pred[-50:] if len(pred) > 50 else pred
                print(f"     Pred: '{pred_short}' | Label: '{label}'")
            
            if val_acc > best_val_acc:
                best_val_acc = val_acc
                patience_counter = 0
                save_checkpoint(
                    model, optimizer, scheduler, epoch,
                    val_loss, val_acc,
                    os.path.join(save_dir, "best_model.pt"),
                    args
                )
            else:
                patience_counter += 1
                print(f"   (æ— æ”¹è¿›, patience: {patience_counter}/{args.early_stop})")
            
            loss_history.append({
                "epoch": epoch,
                "train_loss": train_loss,
                "val_loss": val_loss,
                "val_acc": val_acc,
            })
            
            with open(os.path.join(save_dir, "loss_history.json"), "w") as f:
                json.dump(loss_history, f, indent=2)
        else:
            print(f"Epoch {epoch}: Train Loss = {train_loss:.4f}")
        
        if patience_counter >= args.early_stop:
            print(f"\nâ¹ï¸ æ—©åœ! éªŒè¯å‡†ç¡®ç‡ {args.early_stop} è½®æœªæ”¹è¿›")
            break
    
    print("\n" + "=" * 60)
    print("ğŸ“‹ æœ€ç»ˆæµ‹è¯•è¯„ä¼°...")
    
    best_ckpt = torch.load(os.path.join(save_dir, "best_model.pt"), map_location=device, weights_only=False)
    model.encoder.load_state_dict(best_ckpt["encoder_state"])
    model.projector.load_state_dict(best_ckpt["projector_state"])
    model.load_lora_state_from_checkpoint(best_ckpt, allow_missing=True)
    
    test_results = evaluate(model, test_loader, args.max_new_tokens, "Testing")
    
    print(f"\nâœ… æµ‹è¯•ç»“æœ:")
    print(f"   Test Loss: {test_results['loss']:.4f}")
    print(f"   Test Accuracy: {test_results['accuracy']:.4f}")
    
    final_results = {
        "dataset": args.dataset,
        "best_val_acc": best_val_acc,
        "test_loss": test_results["loss"],
        "test_accuracy": test_results["accuracy"],
        "epochs_trained": epoch,
    }
    
    with open(os.path.join(save_dir, "final_results.json"), "w") as f:
        json.dump(final_results, f, indent=2)
    
    with open(os.path.join(save_dir, "test_predictions.json"), "w") as f:
        json.dump({
            "predictions": test_results["predictions"],
            "labels": test_results["labels"],
        }, f, indent=2)
    
    print("=" * 60)
    print(f"ç»“æœä¿å­˜åˆ°: {save_dir}")
    print("=" * 60)


if __name__ == "__main__":
    main()
