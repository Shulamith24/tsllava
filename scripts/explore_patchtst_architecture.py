#!/usr/bin/env python3
"""
æ¢ç´¢ PatchTST æ¨¡å‹æ¶æ„

ç›®æ ‡ï¼š
1. ç†è§£ PatchTST çš„å‰å‘ä¼ æ’­æµç¨‹
2. åˆ†æ use_cls_token=True çš„ä½œç”¨
3. æŸ¥çœ‹è¾“å‡ºçš„å½¢çŠ¶å’Œç»“æ„
"""

import torch
from transformers import PatchTSTConfig, PatchTSTForClassification, PatchTSTModel

def explore_patchtst_architecture():
    """æ¢ç´¢ PatchTST æ¶æ„"""
    print("=" * 80)
    print("PatchTST æ¶æ„æ¢ç´¢")
    print("=" * 80)
    
    # ========== é…ç½® 1: use_cls_token=True ==========
    print("\n" + "=" * 80)
    print("é…ç½® 1: use_cls_token=True")
    print("=" * 80)
    
    config_with_cls = PatchTSTConfig(
        num_input_channels=1,  # å•å˜é‡æ—¶é—´åºåˆ—
        num_targets=5,  # 5 ç±»åˆ†ç±»
        context_length=128,  # ä¸Šä¸‹æ–‡é•¿åº¦
        patch_length=16,  # æ¯ä¸ª patch çš„é•¿åº¦
        stride=8,  # patch æ­¥é•¿
        d_model=64,  # æ¨¡å‹ç»´åº¦
        num_attention_heads=4,
        num_hidden_layers=2,
        use_cls_token=True,  # ä½¿ç”¨ CLS token
    )
    
    print(f"\né…ç½®å‚æ•°:")
    print(f"  num_input_channels: {config_with_cls.num_input_channels}")
    print(f"  num_targets: {config_with_cls.num_targets}")
    print(f"  context_length: {config_with_cls.context_length}")
    print(f"  patch_length: {config_with_cls.patch_length}")
    print(f"  stride: {config_with_cls.stride}")
    print(f"  d_model: {config_with_cls.d_model}")
    print(f"  num_hidden_layers: {config_with_cls.num_hidden_layers}")
    print(f"  use_cls_token: {config_with_cls.use_cls_token}")
    
    # åˆ›å»ºæ¨¡å‹
    model_with_cls = PatchTSTForClassification(config=config_with_cls)
    print(f"\nâœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ")
    
    # æ‰“å°æ¨¡å‹ç»“æ„
    print(f"\næ¨¡å‹ç»“æ„:")
    for name, module in model_with_cls.named_children():
        print(f"  - {name}: {module.__class__.__name__}")
    
    # åˆ›å»ºæµ‹è¯•è¾“å…¥
    batch_size = 4
    past_values = torch.randn(batch_size, 128, 1)  # [B, L, C]
    print(f"\nè¾“å…¥å½¢çŠ¶: {past_values.shape}")
    print(f"  - batch_size: {batch_size}")
    print(f"  - context_length: 128")
    print(f"  - num_channels: 1")
    
    # å‰å‘ä¼ æ’­
    print(f"\næ‰§è¡Œå‰å‘ä¼ æ’­...")
    model_with_cls.eval()
    with torch.no_grad():
        outputs = model_with_cls(past_values=past_values)
    
    print(f"\nè¾“å‡ºç»“æ„:")
    print(f"  - prediction_logits shape: {outputs.prediction_logits.shape}")
    if outputs.hidden_states is not None:
        print(f"  - hidden_states: {len(outputs.hidden_states)} layers")
    
    # è®¡ç®— patch æ•°é‡
    num_patches = (128 - 16) // 8 + 1
    print(f"\nè®¡ç®—çš„ patch æ•°é‡:")
    print(f"  num_patches = (context_length - patch_length) / stride + 1")
    print(f"  num_patches = (128 - 16) / 8 + 1 = {num_patches}")
    
    # ========== é…ç½® 2: use_cls_token=False ==========
    print("\n" + "=" * 80)
    print("é…ç½® 2: use_cls_token=False")
    print("=" * 80)
    
    config_no_cls = PatchTSTConfig(
        num_input_channels=1,
        num_targets=5,
        context_length=128,
        patch_length=16,
        stride=8,
        d_model=64,
        num_attention_heads=4,
        num_hidden_layers=2,
        use_cls_token=False,  # ä¸ä½¿ç”¨ CLS token
    )
    
    model_no_cls = PatchTSTForClassification(config=config_no_cls)
    print(f"âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ (use_cls_token=False)")
    
    with torch.no_grad():
        outputs_no_cls = model_no_cls(past_values=past_values)
    
    print(f"\nè¾“å‡ºå½¢çŠ¶:")
    print(f"  - prediction_logits: {outputs_no_cls.prediction_logits.shape}")
    
    # ========== å¯¹æ¯”åˆ†æ ==========
    print("\n" + "=" * 80)
    print("å¯¹æ¯”åˆ†æ")
    print("=" * 80)
    
    print(f"\nuse_cls_token=True vs use_cls_token=False:")
    print(f"  CLS=True  logits shape: {outputs.prediction_logits.shape}")
    print(f"  CLS=False logits shape: {outputs_no_cls.prediction_logits.shape}")
    
    return model_with_cls, config_with_cls


def explore_intermediate_outputs():
    """æ¢ç´¢ä¸­é—´å±‚è¾“å‡º"""
    print("\n" + "=" * 80)
    print("æ¢ç´¢ä¸­é—´å±‚è¾“å‡º")
    print("=" * 80)
    
    config = PatchTSTConfig(
        num_input_channels=1,
        num_targets=5,
        context_length=128,
        patch_length=16,
        stride=8,
        d_model=64,
        num_attention_heads=4,
        num_hidden_layers=2,
        use_cls_token=True,
    )
    
    model = PatchTSTForClassification(config=config)
    
    # æµ‹è¯•è¾“å…¥
    past_values = torch.randn(2, 128, 1)
    
    # è·å–æ‰€æœ‰ hidden states
    with torch.no_grad():
        outputs = model(
            past_values=past_values,
            output_hidden_states=True,
            output_attentions=True,
        )
    
    print(f"\nè¯¦ç»†è¾“å‡º:")
    print(f"  prediction_logits: {outputs.prediction_logits.shape}")
    
    if outputs.hidden_states is not None:
        print(f"\n  hidden_states ({len(outputs.hidden_states)} å±‚):")
        for i, hidden in enumerate(outputs.hidden_states):
            print(f"    Layer {i}: {hidden.shape}")
    
    if outputs.attentions is not None:
        print(f"\n  attentions ({len(outputs.attentions)} å±‚):")
        for i, attn in enumerate(outputs.attentions):
            print(f"    Layer {i}: {attn.shape}")
    
    return outputs


def explore_backbone_only():
    """æ¢ç´¢ PatchTSTModelï¼ˆä»… backboneï¼Œä¸å«åˆ†ç±»å¤´ï¼‰"""
    print("\n" + "=" * 80)
    print("æ¢ç´¢ PatchTSTModel (Backbone only)")
    print("=" * 80)
    
    config = PatchTSTConfig(
        num_input_channels=1,
        context_length=128,
        patch_length=16,
        stride=8,
        d_model=64,
        num_attention_heads=4,
        num_hidden_layers=2,
        use_cls_token=True,
    )
    
    # PatchTSTModel ä¸å«åˆ†ç±»å¤´
    backbone = PatchTSTModel(config=config)
    
    print(f"âœ… Backbone åˆ›å»ºæˆåŠŸ")
    print(f"\nBackbone ç»“æ„:")
    for name, module in backbone.named_children():
        print(f"  - {name}: {module.__class__.__name__}")
    
    # æµ‹è¯•
    past_values = torch.randn(2, 128, 1)
    
    with torch.no_grad():
        outputs = backbone(past_values=past_values)
    
    print(f"\nBackbone è¾“å‡º:")
    print(f"  last_hidden_state: {outputs.last_hidden_state.shape}")
    
    # åˆ†æåºåˆ—é•¿åº¦
    seq_len = outputs.last_hidden_state.shape[1]
    num_patches = (128 - 16) // 8 + 1
    
    print(f"\nåºåˆ—é•¿åº¦åˆ†æ:")
    print(f"  è¾“å‡ºåºåˆ—é•¿åº¦: {seq_len}")
    print(f"  é¢„æœŸ patch æ•°: {num_patches}")
    if config.use_cls_token:
        print(f"  = {num_patches} patches + 1 CLS token")
    
    return backbone, outputs


def test_with_different_lengths():
    """æµ‹è¯•ä¸åŒé•¿åº¦çš„è¾“å…¥"""
    print("\n" + "=" * 80)
    print("æµ‹è¯•ä¸åŒé•¿åº¦çš„è¾“å…¥")
    print("=" * 80)
    
    config = PatchTSTConfig(
        num_input_channels=1,
        num_targets=5,
        context_length=256,  # æ›´é•¿çš„ä¸Šä¸‹æ–‡
        patch_length=16,
        stride=8,
        d_model=64,
        use_cls_token=True,
    )
    
    model = PatchTSTForClassification(config=config)
    
    test_cases = [
        (64, 1),
        (128, 1),
        (256, 1),
    ]
    
    for length, channels in test_cases:
        past_values = torch.randn(2, length, channels)
        
        try:
            with torch.no_grad():
                outputs = model(past_values=past_values)
            
            num_patches = (length - 16) // 8 + 1
            print(f"\nè¾“å…¥é•¿åº¦={length}:")
            print(f"  é¢„æœŸ patches: {num_patches}")
            print(f"  è¾“å‡º logits: {outputs.prediction_logits.shape}")
            print(f"  âœ… æˆåŠŸ")
        except Exception as e:
            print(f"\nè¾“å…¥é•¿åº¦={length}:")
            print(f"  âŒ å¤±è´¥: {e}")


def main():
    print("\n" + "ğŸ”" * 40)
    print("PatchTST æ¶æ„æ·±åº¦æ¢ç´¢")
    print("ğŸ”" * 40)
    
    try:
        # 1. åŸºæœ¬æ¶æ„æ¢ç´¢
        model, config = explore_patchtst_architecture()
        
        # 2. ä¸­é—´å±‚è¾“å‡º
        outputs = explore_intermediate_outputs()
        
        # 3. Backbone æ¢ç´¢
        backbone, backbone_outputs = explore_backbone_only()
        
        # 4. ä¸åŒé•¿åº¦æµ‹è¯•
        test_with_different_lengths()
        
        # ========== æ€»ç»“ ==========
        print("\n" + "=" * 80)
        print("æ€»ç»“")
        print("=" * 80)
        
        print(f"\n**use_cls_token=True æ—¶çš„å‰å‘ä¼ æ’­æµç¨‹**:")
        print(f"")
        print(f"1. è¾“å…¥: past_values [batch_size, context_length, num_channels]")
        print(f"")
        print(f"2. Patching:")
        print(f"   - å°†æ—¶é—´åºåˆ—åˆ‡åˆ†ä¸º patches")
        print(f"   - num_patches = (context_length - patch_length) / stride + 1")
        print(f"   - æ¯ä¸ª patch åµŒå…¥åˆ° d_model ç»´")
        print(f"")
        print(f"3. CLS Token æ·»åŠ :")
        print(f"   - åœ¨ patch embeddings å‰æ·»åŠ ä¸€ä¸ªå¯å­¦ä¹ çš„ CLS token")
        print(f"   - åºåˆ—å˜ä¸º: [CLS] + [Patch_1, Patch_2, ..., Patch_N]")
        print(f"   - åºåˆ—é•¿åº¦: num_patches + 1")
        print(f"")
        print(f"4. Transformer Encoder:")
        print(f"   - å¤šå±‚ self-attention")
        print(f"   - è¾“å‡º: [batch_size, num_patches+1, d_model]")
        print(f"")
        print(f"5. åˆ†ç±» (use_cls_token=True):")
        print(f"   - æå– CLS token çš„è¾“å‡º: output[:, 0, :]")
        print(f"   - é€šè¿‡åˆ†ç±»å¤´: Linear(d_model -> num_targets)")
        print(f"   - è¾“å‡º: [batch_size, num_targets]")
        print(f"")
        print(f"6. åˆ†ç±» (use_cls_token=False):")
        print(f"   - å¯¹æ‰€æœ‰ patch è¾“å‡ºå–å¹³å‡: output.mean(dim=1)")
        print(f"   - é€šè¿‡åˆ†ç±»å¤´")
        print(f"   - è¾“å‡º: [batch_size, num_targets]")
        
        print("\n" + "=" * 80)
        print("âœ… æ¢ç´¢å®Œæˆ!")
        print("=" * 80)
        
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main())
