#!/usr/bin/env python3
"""
æµ‹è¯• OpenTSLMClassifierMultiANS æ¨¡å‹

å¿«é€ŸéªŒè¯ï¼š
1. æ¨¡å‹å¯ä»¥æ­£ç¡®åˆå§‹åŒ–ï¼ˆM=1, M=4, M=8ï¼‰
2. forward pass å¯ä»¥è¿”å›æŸå¤±
3. predict å¯ä»¥è¿”å›é¢„æµ‹ç±»åˆ«
4. token-wise normalization å’Œ averaging logits æ­£ç¡®å·¥ä½œ
"""

import sys
from pathlib import Path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root / "src"))

import torch
from opentslm.model.llm.OpenTSLMClassifierMultiANS import OpenTSLMClassifierMultiANS
from opentslm.time_series_datasets.ucr.UCRClassificationDataset import UCRClassificationDataset
from opentslm.time_series_datasets.util import extend_time_series_to_match_patch_size_and_aggregate
from opentslm.model_config import PATCH_SIZE


def test_model_initialization():
    """æµ‹è¯•æ¨¡å‹åˆå§‹åŒ–ï¼ˆä¸åŒ ANS tokens æ•°é‡ï¼‰"""
    print("=" * 60)
    print("æµ‹è¯• 1: æ¨¡å‹åˆå§‹åŒ–")
    print("=" * 60)
    
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    for num_ans in [1, 4, 8]:
        print(f"\næµ‹è¯• num_ans_tokens={num_ans}:")
        
        model = OpenTSLMClassifierMultiANS(
            num_classes=5,
            num_ans_tokens=num_ans,
            llm_id="meta-llama/Llama-3.2-1B",
            device=device,
            encoder_type="transformer_cnn",
        )
        
        print(f"  âœ“ æ¨¡å‹åˆ›å»ºæˆåŠŸ")
        print(f"    - ç±»åˆ«æ•°: {model.num_classes}")
        print(f"    - ANS tokens: {num_ans}")
        print(f"    - ANS tokens shape: {model.ans_tokens.shape}")
        print(f"    - Token norm: {model.token_norm}")
    
    return model, device


def test_forward_pass(device):
    """æµ‹è¯•å‰å‘ä¼ æ’­ï¼ˆä¸åŒ ANS tokens æ•°é‡ï¼‰"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 2: å‰å‘ä¼ æ’­ï¼ˆä¸åŒ ANS tokens æ•°é‡ï¼‰")
    print("=" * 60)
    
    batch = [
        {
            "time_series": [torch.randn(100, device=device)],
            "int_label": 0,
        },
        {
            "time_series": [torch.randn(120, device=device)],
            "int_label": 2,
        },
    ]
    
    for num_ans in [1, 4, 8]:
        print(f"\nnum_ans_tokens={num_ans}:")
        
        model = OpenTSLMClassifierMultiANS(
            num_classes=5,
            num_ans_tokens=num_ans,
            llm_id="meta-llama/Llama-3.2-1B",
            device=device,
            encoder_type="transformer_cnn",
        )
        
        model.train()
        loss = model(batch)
        
        print(f"  âœ“ å‰å‘ä¼ æ’­æˆåŠŸ")
        print(f"    - æŸå¤±å€¼: {loss.item():.4f}")
        print(f"    - æŸå¤±æ˜¯å¦ä¸ºæ ‡é‡: {loss.dim() == 0}")
        print(f"    - æŸå¤± requires_grad: {loss.requires_grad}")


def test_prediction(device):
    """æµ‹è¯•é¢„æµ‹ï¼ˆä¸åŒ ANS tokens æ•°é‡ï¼‰"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 3: é¢„æµ‹ï¼ˆä¸åŒ ANS tokens æ•°é‡ï¼‰")
    print("=" * 60)
    
    batch = [
        {
            "time_series": [torch.randn(100, device=device)],
            "int_label": 1,
        },
        {
            "time_series": [torch.randn(150, device=device)],
            "int_label": 3,
        },
        {
            "time_series": [torch.randn(80, device=device)],
            "int_label": 4,
        },
    ]
    
    for num_ans in [4, 8]:
        print(f"\nnum_ans_tokens={num_ans}:")
        
        model = OpenTSLMClassifierMultiANS(
            num_classes=5,
            num_ans_tokens=num_ans,
            llm_id="meta-llama/Llama-3.2-1B",
            device=device,
            encoder_type="transformer_cnn",
        )
        
        model.eval()
        with torch.no_grad():
            predictions = model.predict(batch)
        
        print(f"  âœ“ é¢„æµ‹æˆåŠŸ")
        print(f"    - é¢„æµ‹ shape: {predictions.shape}")
        print(f"    - é¢„æµ‹å€¼: {predictions.tolist()}")
        print(f"    - çœŸå®æ ‡ç­¾: {[b['int_label'] for b in batch]}")
        
        assert all(0 <= p < model.num_classes for p in predictions.tolist()), "é¢„æµ‹å€¼è¶…å‡ºèŒƒå›´"
        print(f"    - æ‰€æœ‰é¢„æµ‹åœ¨æœ‰æ•ˆèŒƒå›´ [0, {model.num_classes-1}]")


def test_with_real_dataset():
    """æµ‹è¯•ä½¿ç”¨çœŸå® UCR æ•°æ®é›†"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 4: ä½¿ç”¨çœŸå® UCR æ•°æ®é›†ï¼ˆM=1, M=4ï¼‰")
    print("=" * 60)
    
    try:
        device = "cuda" if torch.cuda.is_available() else "cpu"
        
        # åˆ›å»ºæ•°æ®é›†
        print("åŠ è½½ ECG200 æ•°æ®é›†...")
        dataset = UCRClassificationDataset(
            split="train",
            EOS_TOKEN="<eos>",
            dataset_name="ECG200",
            raw_data_path="./data",
        )
        
        num_classes = UCRClassificationDataset.get_num_classes()
        print(f"âœ“ æ•°æ®é›†åŠ è½½æˆåŠŸ")
        print(f"  - æ•°æ®é›†å¤§å°: {len(dataset)}")
        print(f"  - ç±»åˆ«æ•°: {num_classes}")
        
        # æµ‹è¯• M=1 å’Œ M=4
        for num_ans in [1, 4]:
            print(f"\næµ‹è¯• num_ans_tokens={num_ans}:")
            
            # åˆ›å»ºæ¨¡å‹
            model = OpenTSLMClassifierMultiANS(
                num_classes=num_classes,
                num_ans_tokens=num_ans,
                llm_id="meta-llama/Llama-3.2-1B",
                device=device,
                encoder_type="transformer_cnn",
            )
            print(f"  âœ“ æ¨¡å‹åˆ›å»ºæˆåŠŸ")
            
            # è·å–æ‰¹æ¬¡
            samples = [dataset[i] for i in range(min(2, len(dataset)))]
            batch = extend_time_series_to_match_patch_size_and_aggregate(samples, patch_size=PATCH_SIZE)
            
            # æµ‹è¯•å‰å‘ä¼ æ’­
            model.train()
            loss = model(batch)
            print(f"  âœ“ å‰å‘ä¼ æ’­æˆåŠŸï¼ŒæŸå¤±: {loss.item():.4f}")
            
            # æµ‹è¯•é¢„æµ‹
            model.eval()
            with torch.no_grad():
                predictions = model.predict(batch)
            
            print(f"  âœ“ é¢„æµ‹æˆåŠŸ")
            for i, (pred, sample) in enumerate(zip(predictions.tolist(), batch)):
                print(f"    æ ·æœ¬ {i}: é¢„æµ‹={pred}, çœŸå®={sample['int_label']}")
        
        print("\nâœ… æ‰€æœ‰çœŸå®æ•°æ®é›†æµ‹è¯•é€šè¿‡!")
        
    except Exception as e:
        print(f"âš ï¸ çœŸå®æ•°æ®é›†æµ‹è¯•è·³è¿‡ï¼ˆéœ€è¦ä¸‹è½½æ•°æ®ï¼‰: {e}")


def main():
    print("\n" + "ğŸ§ª" * 30)
    print("OpenTSLMClassifierMultiANS å•å…ƒæµ‹è¯•")
    print("ğŸ§ª" * 30 + "\n")
    
    try:
        # æµ‹è¯• 1: åˆå§‹åŒ–
        model, device = test_model_initialization()
        
        # æµ‹è¯• 2: å‰å‘ä¼ æ’­
        test_forward_pass(device)
        
        # æµ‹è¯• 3: é¢„æµ‹
        test_prediction(device)
        
        # æµ‹è¯• 4: çœŸå®æ•°æ®é›†
        test_with_real_dataset()
        
        print("\n" + "=" * 60)
        print("âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
        print("=" * 60)
        print("\nä¸‹ä¸€æ­¥: è¿è¡Œå®Œæ•´è®­ç»ƒè„šæœ¬")
        print("  # M=4")
        print("  python scripts/train_ucr_classification_experiment_c.py \\")
        print("      --dataset Adiac \\")
        print("      --num_ans_tokens 4 \\")
        print("      --epochs 5 \\")
        print("      --batch_size 8")
        print()
        print("  # M=8")
        print("  python scripts/train_ucr_classification_experiment_c.py \\")
        print("      --dataset Adiac \\")
        print("      --num_ans_tokens 8 \\")
        print("      --epochs 5 \\")
        print("      --batch_size 8")
        
    except Exception as e:
        print("\n" + "=" * 60)
        print("âŒ æµ‹è¯•å¤±è´¥!")
        print("=" * 60)
        print(f"é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main())
