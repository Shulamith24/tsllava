#!/usr/bin/env python3
"""
æµ‹è¯• OpenTSLMClassifier æ¨¡å‹

å¿«é€ŸéªŒè¯ï¼š
1. æ¨¡å‹å¯ä»¥æ­£ç¡®åˆå§‹åŒ–
2. forward pass å¯ä»¥è¿”å›æŸå¤±
3. predict å¯ä»¥è¿”å›é¢„æµ‹ç±»åˆ«
"""

import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root / "src"))

import torch
from opentslm.model.llm.OpenTSLMClassifier import OpenTSLMClassifier
from opentslm.time_series_datasets.ucr.UCRClassificationDataset import UCRClassificationDataset
from opentslm.time_series_datasets.util import extend_time_series_to_match_patch_size_and_aggregate
from opentslm.model_config import PATCH_SIZE


def test_model_initialization():
    """æµ‹è¯•æ¨¡å‹åˆå§‹åŒ–"""
    print("=" * 60)
    print("æµ‹è¯• 1: æ¨¡å‹åˆå§‹åŒ–")
    print("=" * 60)
    
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åˆ›å»ºæ¨¡å‹
    model = OpenTSLMClassifier(
        num_classes=5,
        llm_id="meta-llama/Llama-3.2-1B",
        device=device,
        encoder_type="transformer_cnn",
    )
    
    print(f"âœ“ æ¨¡å‹åˆ›å»ºæˆåŠŸ")
    print(f"  - ç±»åˆ«æ•°: {model.num_classes}")
    print(f"  - [ANS] token shape: {model.ans_token.shape}")
    print(f"  - åˆ†ç±»å¤´: {model.classifier_head}")
    
    return model, device


def test_forward_pass(model, device):
    """æµ‹è¯•å‰å‘ä¼ æ’­"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 2: å‰å‘ä¼ æ’­ï¼ˆè®¡ç®—æŸå¤±ï¼‰")
    print("=" * 60)
    
    # åˆ›å»ºæ¨¡æ‹Ÿæ‰¹æ¬¡
    batch = [
        {
            "pre_prompt": "Classify the time series:",
            "time_series_text": ["This is test data:"],
            "time_series": [torch.randn(100, device=device)],
            "post_prompt": "\nClass:",
            "int_label": 0,
        },
        {
            "pre_prompt": "Classify the time series:",
            "time_series_text": ["This is test data:"],
            "time_series": [torch.randn(120, device=device)],
            "post_prompt": "\nClass:",
            "int_label": 2,
        },
    ]
    
    # è®¡ç®—æŸå¤±
    model.train()
    loss = model(batch)
    
    print(f"âœ“ å‰å‘ä¼ æ’­æˆåŠŸ")
    print(f"  - æŸå¤±å€¼: {loss.item():.4f}")
    print(f"  - æŸå¤±æ˜¯å¦ä¸ºæ ‡é‡: {loss.dim() == 0}")
    print(f"  - æŸå¤± requires_grad: {loss.requires_grad}")
    
    return loss


def test_prediction(model, device):
    """æµ‹è¯•é¢„æµ‹"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 3: é¢„æµ‹")
    print("=" * 60)
    
    # åˆ›å»ºæ¨¡æ‹Ÿæ‰¹æ¬¡
    batch = [
        {
            "pre_prompt": "Classify the time series:",
            "time_series_text": ["This is test data:"],
            "time_series": [torch.randn(100, device=device)],
            "post_prompt": "\nClass:",
            "int_label": 1,
        },
        {
            "pre_prompt": "Classify the time series:",
            "time_series_text": ["This is test data:"],
            "time_series": [torch.randn(150, device=device)],
            "post_prompt": "\nClass:",
            "int_label": 3,
        },
        {
            "pre_prompt": "Classify the time series:",
            "time_series_text": ["This is test data:"],
            "time_series": [torch.randn(80, device=device)],
            "post_prompt": "\nClass:",
            "int_label": 4,
        },
    ]
    
    # é¢„æµ‹
    model.eval()
    with torch.no_grad():
        predictions = model.predict(batch)
    
    print(f"âœ“ é¢„æµ‹æˆåŠŸ")
    print(f"  - é¢„æµ‹ shape: {predictions.shape}")
    print(f"  - é¢„æµ‹å€¼: {predictions.tolist()}")
    print(f"  - çœŸå®æ ‡ç­¾: {[b['int_label'] for b in batch]}")
    
    # æ£€æŸ¥é¢„æµ‹åœ¨æœ‰æ•ˆèŒƒå›´å†…
    assert all(0 <= p < model.num_classes for p in predictions.tolist()), "é¢„æµ‹å€¼è¶…å‡ºèŒƒå›´"
    print(f"  - æ‰€æœ‰é¢„æµ‹åœ¨æœ‰æ•ˆèŒƒå›´ [0, {model.num_classes-1}]")
    
    return predictions


def test_with_real_dataset():
    """æµ‹è¯•ä½¿ç”¨çœŸå® UCR æ•°æ®é›†"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 4: ä½¿ç”¨çœŸå® UCR æ•°æ®é›†")
    print("=" * 60)
    
    try:
        device = "cuda" if torch.cuda.is_available() else "cpu"
        
        # åˆ›å»ºæ•°æ®é›†
        print("åŠ è½½ ECG200 æ•°æ®é›†...")
        dataset = UCRClassificationDataset(
            split="train",
            EOS_TOKEN="<eos>",
            dataset_name="ECG200",
            raw_data_path="./data",
        )
        
        num_classes = UCRClassificationDataset.get_num_classes()
        print(f"âœ“ æ•°æ®é›†åŠ è½½æˆåŠŸ")
        print(f"  - æ•°æ®é›†å¤§å°: {len(dataset)}")
        print(f"  - ç±»åˆ«æ•°: {num_classes}")
        
        # åˆ›å»ºæ¨¡å‹
        print("\nåˆ›å»ºæ¨¡å‹...")
        model = OpenTSLMClassifier(
            num_classes=num_classes,
            llm_id="meta-llama/Llama-3.2-1B",
            device=device,
            encoder_type="transformer_cnn",
        )
        print(f"âœ“ æ¨¡å‹åˆ›å»ºæˆåŠŸ")
        
        # è·å–ä¸€ä¸ªå°æ‰¹æ¬¡
        print("\nå¤„ç†æ‰¹æ¬¡æ•°æ®...")
        samples = [dataset[i] for i in range(min(2, len(dataset)))]
        batch = extend_time_series_to_match_patch_size_and_aggregate(samples, patch_size=PATCH_SIZE)
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        print("\næµ‹è¯•å‰å‘ä¼ æ’­...")
        model.train()
        loss = model(batch)
        print(f"âœ“ å‰å‘ä¼ æ’­æˆåŠŸï¼ŒæŸå¤±: {loss.item():.4f}")
        
        # æµ‹è¯•é¢„æµ‹
        print("\næµ‹è¯•é¢„æµ‹...")
        model.eval()
        with torch.no_grad():
            predictions = model.predict(batch)
        
        print(f"âœ“ é¢„æµ‹æˆåŠŸ")
        for i, (pred, sample) in enumerate(zip(predictions.tolist(), batch)):
            print(f"  æ ·æœ¬ {i}: é¢„æµ‹={pred}, çœŸå®={sample['int_label']}")
        
        print("\nâœ… æ‰€æœ‰çœŸå®æ•°æ®é›†æµ‹è¯•é€šè¿‡!")
        
    except Exception as e:
        print(f"âš ï¸ çœŸå®æ•°æ®é›†æµ‹è¯•è·³è¿‡ï¼ˆéœ€è¦ä¸‹è½½æ•°æ®ï¼‰: {e}")


def main():
    print("\n" + "ğŸ§ª" * 30)
    print("OpenTSLMClassifier å•å…ƒæµ‹è¯•")
    print("ğŸ§ª" * 30 + "\n")
    
    try:
        # æµ‹è¯• 1: åˆå§‹åŒ–
        model, device = test_model_initialization()
        
        # æµ‹è¯• 2: å‰å‘ä¼ æ’­
        loss = test_forward_pass(model, device)
        
        # æµ‹è¯• 3: é¢„æµ‹
        predictions = test_prediction(model, device)
        
        # æµ‹è¯• 4: çœŸå®æ•°æ®é›†ï¼ˆå¯é€‰ï¼‰
        test_with_real_dataset()
        
        print("\n" + "=" * 60)
        print("âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
        print("=" * 60)
        print("\nä¸‹ä¸€æ­¥: è¿è¡Œå®Œæ•´è®­ç»ƒè„šæœ¬")
        print("  python scripts/train_ucr_classification_experiment_a.py \\")
        print("      --dataset CricketZ \\")
        print("      --epochs 5 \\")
        print("      --batch_size 8")
        
    except Exception as e:
        print("\n" + "=" * 60)
        print("âŒ æµ‹è¯•å¤±è´¥!")
        print("=" * 60)
        print(f"é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main())
