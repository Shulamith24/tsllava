#!/usr/bin/env python3
# SPDX-FileCopyrightText: 2025 Stanford University, ETH Zurich, and the project authors
# SPDX-License-Identifier: MIT

"""
å¤šæ•°æ®é›†ç»Ÿä¸€Prototypeåˆ†ç±»è®­ç»ƒè„šæœ¬

ç‰¹ç‚¹:
1. ä»é…ç½®æ–‡ä»¶åŠ è½½å¤šä¸ªUCRæ•°æ®é›†
2. æ¯æ•°æ®é›†ç‹¬ç«‹çš„ Prompt (PromptBank) + Prototype (PrototypeBank)
3. Episodicé‡‡æ ·ï¼šä¸€ä¸ªbatchä¸€ä¸ªdatasetï¼Œæ¸©åº¦é‡‡æ ·å¹³è¡¡å¤§å°å·®å¼‚
4. ä¸¤é˜¶æ®µè®­ç»ƒï¼šStage 0 å†»ç»“ä¸»å¹²ï¼ŒStage 1 è”åˆè®­ç»ƒ
5. è¯„ä¼°æŒ‡æ ‡ï¼šMacro average + Worst-10%

ä½¿ç”¨æ–¹æ³•:
    # Stage 0 (å¯¹é½ task tokens)
    python scripts/train_multi_dataset_prototype.py \
        --pretrained_model OpenTSLM/llama-3.2-1b-m4-sp \
        --config configs/multi_dataset_ucr.txt \
        --stage 0 \
        --epochs 5

    # Stage 1 (è”åˆè®­ç»ƒ)
    python scripts/train_multi_dataset_prototype.py \
        --pretrained_model OpenTSLM/llama-3.2-1b-m4-sp \
        --config configs/multi_dataset_ucr.txt \
        --stage 1 \
        --resume_from results/multi_dataset/stage0_best.pt \
        --epochs 30
"""

import os
import sys
import json
import argparse
import datetime
from pathlib import Path
from typing import List, Dict, Any

import torch
import torch.distributed as dist
from torch.nn.parallel import DistributedDataParallel as DDP
from torch.optim import AdamW
from torch.nn.utils import clip_grad_norm_
from torch.utils.data import DataLoader
from tqdm.auto import tqdm
from transformers import get_linear_schedule_with_warmup

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root / "src"))

from opentslm.model.llm.OpenTSLM import OpenTSLM
from opentslm.model.llm.OpenTSLMMultiDataset import OpenTSLMMultiDataset
from opentslm.time_series_datasets.multi_dataset import (
    MultiDatasetRegistry,
    UnifiedPrototypeDataset,
)
from opentslm.time_series_datasets.episodic_sampler import EpisodicBatchSampler
from opentslm.time_series_datasets.util import extend_time_series_to_match_patch_size_and_aggregate
from opentslm.model_config import PATCH_SIZE, ENCODER_OUTPUT_DIM


def parse_args():
    parser = argparse.ArgumentParser(description="å¤šæ•°æ®é›†ç»Ÿä¸€Prototypeåˆ†ç±»è®­ç»ƒ")
    
    # æ•°æ®ç›¸å…³
    parser.add_argument("--config", type=str, default="configs/multi_dataset_ucr.txt",
                        help="æ•°æ®é›†é…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--data_path", type=str, default="./data", help="UCRæ•°æ®æ ¹ç›®å½•")
    parser.add_argument("--alpha", type=float, default=0.4,
                        help="æ¸©åº¦é‡‡æ ·å‚æ•°: 0=å‡åŒ€, 0.3-0.5=æŠ˜ä¸­, 1=æŒ‰æ•°æ®é‡")
    
    # æ¨¡å‹ç›¸å…³
    parser.add_argument("--pretrained_model", type=str, default=None,
                        help="é¢„è®­ç»ƒæ¨¡å‹ID (HuggingFace repo_id)")
    parser.add_argument("--local_checkpoint", type=str, default=None,
                        help="æœ¬åœ°checkpointè·¯å¾„")
    parser.add_argument("--encoder_type", type=str, default="transformer_cnn",
                        choices=["transformer_cnn", "tslanet"])
    parser.add_argument("--llm_id", type=str, default="meta-llama/Llama-3.2-1B")
    
    # Prototypeç›¸å…³
    parser.add_argument("--prompt_len", type=int, default=10, help="å¯å­¦ä¹ Prompté•¿åº¦")
    parser.add_argument("--init_temperature", type=float, default=1.0, help="æ¸©åº¦åˆå§‹å€¼")
    
    # LoRAç›¸å…³
    parser.add_argument("--no_lora", action="store_true", help="ç¦ç”¨LoRA")
    parser.add_argument("--lora_r", type=int, default=16, help="LoRA rank")
    parser.add_argument("--lora_alpha", type=int, default=32, help="LoRA alpha")
    
    # è®­ç»ƒé˜¶æ®µ
    parser.add_argument("--stage", type=int, default=0, choices=[0, 1],
                        help="è®­ç»ƒé˜¶æ®µ: 0=åªè®­ç»ƒå¤´éƒ¨, 1=è”åˆè®­ç»ƒ")
    parser.add_argument("--resume_from", type=str, default=None,
                        help="ä»checkpointåŠ è½½æ¨¡å‹æƒé‡")
    
    # è®­ç»ƒè¶…å‚
    parser.add_argument("--epochs", type=int, default=30)
    parser.add_argument("--batch_size", type=int, default=32)
    parser.add_argument("--lr_prompt_bank", type=float, default=1e-3, help="PromptBankå­¦ä¹ ç‡")
    parser.add_argument("--lr_prototype_bank", type=float, default=1e-3, help="PrototypeBankå­¦ä¹ ç‡")
    parser.add_argument("--lr_cls", type=float, default=1e-3, help="CLSç›¸å…³å­¦ä¹ ç‡")
    parser.add_argument("--lr_encoder", type=float, default=2e-4, help="Encoderå­¦ä¹ ç‡")
    parser.add_argument("--lr_projector", type=float, default=1e-4, help="Projectorå­¦ä¹ ç‡")
    parser.add_argument("--lr_lora", type=float, default=1e-4, help="LoRAå­¦ä¹ ç‡")
    parser.add_argument("--weight_decay", type=float, default=1e-2)
    parser.add_argument("--grad_clip", type=float, default=1.0)
    parser.add_argument("--warmup_ratio", type=float, default=0.1)
    
    # ä¿å­˜ç›¸å…³
    parser.add_argument("--save_dir", type=str, default="results/multi_dataset")
    
    # å…¶ä»–
    parser.add_argument("--seed", type=int, default=42)
    parser.add_argument("--device", type=str, default="cuda")
    parser.add_argument("--eval_every", type=int, default=5)
    parser.add_argument("--early_stop", type=int, default=10)
    parser.add_argument("--eval_batch_size", type=int, default=32)
    parser.add_argument("--gradient_accumulation_steps", type=int, default=1)
    parser.add_argument("--gradient_checkpointing", action="store_true")
    
    return parser.parse_args()


def setup_distributed():
    """åˆå§‹åŒ–åˆ†å¸ƒå¼ç¯å¢ƒ"""
    if "LOCAL_RANK" in os.environ:
        local_rank = int(os.environ["LOCAL_RANK"])
        world_size = int(os.environ.get("WORLD_SIZE", 1))
        rank = int(os.environ.get("RANK", 0))
        torch.cuda.set_device(local_rank)
        dist.init_process_group(backend="nccl", init_method="env://")
        return local_rank, world_size, rank
    return 0, 1, 0


def cleanup_distributed():
    if dist.is_initialized():
        dist.destroy_process_group()


def get_model(model):
    return model.module if hasattr(model, "module") else model


def set_seed(seed: int):
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)


def collate_fn(batch):
    """æ•´ç†æ‰¹æ¬¡æ•°æ®"""
    processed = extend_time_series_to_match_patch_size_and_aggregate(
        batch, patch_size=PATCH_SIZE
    )
    return processed


def train_one_epoch(
    model,
    train_loader: DataLoader,
    optimizer,
    scheduler,
    grad_clip: float,
    epoch: int,
    num_epochs: int,
    gradient_accumulation_steps: int = 1,
    rank: int = 0,
) -> float:
    """è®­ç»ƒä¸€ä¸ªepoch"""
    model.train()
    total_loss = 0.0
    num_batches = 0
    optimizer.zero_grad()
    
    pbar = tqdm(train_loader, desc=f"Epoch {epoch}/{num_epochs}", disable=(rank != 0))
    for step, batch in enumerate(pbar):
        loss = model(batch)
        loss = loss / gradient_accumulation_steps
        
        loss.backward()
        
        if (step + 1) % gradient_accumulation_steps == 0:
            clip_grad_norm_(model.parameters(), max_norm=grad_clip)
            optimizer.step()
            scheduler.step()
            optimizer.zero_grad()
        
        total_loss += loss.item() * gradient_accumulation_steps
        num_batches += 1
        
        if rank == 0:
            pbar.set_postfix({
                "loss": f"{loss.item() * gradient_accumulation_steps:.4f}",
                "lr": f"{scheduler.get_last_lr()[0]:.2e}"
            })
    
    # å¤„ç†æœ€åä¸è¶³accumulation_stepsçš„batch
    if num_batches % gradient_accumulation_steps != 0:
        clip_grad_norm_(model.parameters(), max_norm=grad_clip)
        optimizer.step()
        scheduler.step()
        optimizer.zero_grad()
    
    return total_loss / max(num_batches, 1)


@torch.no_grad()
def evaluate_multi_dataset(
    model,
    registry: MultiDatasetRegistry,
    split: str = "test",
    batch_size: int = 32,
    rank: int = 0,
) -> Dict[str, Any]:
    """
    è¯„ä¼°å¤šæ•°æ®é›†
    
    è¿”å›:
        - per_dataset: æ¯ä¸ªæ•°æ®é›†çš„accuracy
        - macro_avg: å®å¹³å‡accuracy
        - worst_10_pct: æœ€å·®10%æ•°æ®é›†çš„å¹³å‡accuracy
    """
    underlying_model = get_model(model)
    underlying_model.eval()
    
    per_dataset_results = {}
    
    for ds_info in registry.get_all_datasets():
        # åˆ›å»ºè¯¥æ•°æ®é›†çš„DataLoader
        dataset = UnifiedPrototypeDataset(registry, split=split)
        indices = dataset.get_indices_for_dataset(ds_info.ds_id)
        
        if len(indices) == 0:
            continue
        
        # åˆ›å»ºå­é›†DataLoader
        subset_data = [dataset[i] for i in indices]
        
        total_correct = 0
        total_samples = 0
        total_loss = 0.0
        num_batches = 0
        
        # åˆ†æ‰¹å¤„ç†
        for i in range(0, len(subset_data), batch_size):
            batch = subset_data[i:i+batch_size]
            batch = collate_fn(batch)
            
            loss, logits = underlying_model.forward_prototype(batch)
            predictions = logits.argmax(dim=-1)
            labels = torch.tensor([s["label_index"] for s in batch], device=logits.device)
            
            total_loss += loss.item()
            total_correct += (predictions == labels).sum().item()
            total_samples += len(batch)
            num_batches += 1
        
        accuracy = total_correct / total_samples if total_samples > 0 else 0.0
        avg_loss = total_loss / num_batches if num_batches > 0 else 0.0
        
        per_dataset_results[ds_info.name] = {
            "accuracy": accuracy,
            "loss": avg_loss,
            "num_samples": total_samples,
            "temperature": underlying_model.prototype_bank.get_temperature(ds_info.ds_id),
        }
    
    # è®¡ç®—å®å¹³å‡
    accuracies = [r["accuracy"] for r in per_dataset_results.values()]
    macro_avg = sum(accuracies) / len(accuracies) if accuracies else 0.0
    
    # è®¡ç®—æœ€å·®10%
    sorted_acc = sorted(accuracies)
    num_worst = max(1, len(sorted_acc) // 10)
    worst_10_pct = sum(sorted_acc[:num_worst]) / num_worst if sorted_acc else 0.0
    
    return {
        "per_dataset": per_dataset_results,
        "macro_avg": macro_avg,
        "worst_10_pct": worst_10_pct,
    }


def save_checkpoint(
    model,
    optimizer,
    scheduler,
    epoch: int,
    macro_acc: float,
    save_path: str,
    args,
    rank: int = 0,
):
    """ä¿å­˜checkpoint"""
    if rank != 0:
        return
    
    underlying_model = get_model(model)
    checkpoint = {
        "encoder_state": underlying_model.encoder.state_dict(),
        "projector_state": underlying_model.projector.state_dict(),
        "prompt_bank_state": underlying_model.prompt_bank.state_dict(),
        "prototype_bank_state": underlying_model.prototype_bank.state_dict(),
        "cls_embed": underlying_model.cls_embed.data,
        "cls_projector_state": underlying_model.cls_projector.state_dict(),
        "optimizer_state": optimizer.state_dict(),
        "scheduler_state": scheduler.state_dict(),
        "epoch": epoch,
        "macro_acc": macro_acc,
        "args": vars(args),
    }
    
    underlying_model.save_lora_state_to_checkpoint(checkpoint)
    torch.save(checkpoint, save_path)
    print(f"ğŸ’¾ Saved checkpoint to: {save_path}")


def main():
    args = parse_args()
    
    # åˆå§‹åŒ–åˆ†å¸ƒå¼
    local_rank, world_size, rank = setup_distributed()
    
    if rank == 0:
        print("=" * 60)
        print("å¤šæ•°æ®é›†ç»Ÿä¸€Prototypeåˆ†ç±»è®­ç»ƒ")
        print("=" * 60)
        print(f"æ—¶é—´: {datetime.datetime.now()}")
        print(f"é…ç½®: {args.config}")
        print(f"Stage: {args.stage}")
        print(f"Alpha: {args.alpha}")
        print(f"Prompté•¿åº¦: {args.prompt_len}")
        print(f"LoRA: {not args.no_lora}")
        print("=" * 60)
    
    set_seed(args.seed + rank)
    
    # è®¾å¤‡
    if world_size > 1:
        device = f"cuda:{local_rank}"
    elif args.device == "cuda" and torch.cuda.is_available():
        device = "cuda"
    else:
        device = "cpu"
        if rank == 0:
            print("âš ï¸ ä½¿ç”¨CPU")
    
    # ä¿å­˜ç›®å½•
    save_dir = args.save_dir
    if rank == 0:
        os.makedirs(save_dir, exist_ok=True)
        with open(os.path.join(save_dir, f"config_stage{args.stage}.json"), "w") as f:
            json.dump(vars(args), f, indent=2)
    
    if world_size > 1:
        dist.barrier()
    
    # åŠ è½½æ•°æ®é›†æ³¨å†Œè¡¨
    if rank == 0:
        print("\nğŸ“‚ åŠ è½½æ•°æ®é›†...")
    registry = MultiDatasetRegistry(data_path=args.data_path)
    registry.load_from_file(args.config)
    
    # åˆ›å»ºæ¨¡å‹
    if rank == 0:
        print("\nğŸ”§ åˆ›å»ºæ¨¡å‹...")
    
    use_lora = not args.no_lora
    
    if args.pretrained_model:
        # ä»HuggingFaceåŠ è½½åŸºç¡€æƒé‡
        if rank == 0:
            print(f"ğŸ“‚ ä»HuggingFaceåŠ è½½: {args.pretrained_model}")
        
        base_model = OpenTSLM.load_pretrained(
            repo_id=args.pretrained_model,
            device=device,
            enable_lora=False,
        )
        
        # åˆ›å»ºå¤šæ•°æ®é›†æ¨¡å‹
        model = OpenTSLMMultiDataset(
            registry=registry,
            llm_id=base_model.llm.config._name_or_path if hasattr(base_model.llm.config, '_name_or_path') else "meta-llama/Llama-3.2-1B",
            device=device,
            encoder_type="transformer_cnn",
            prompt_len=args.prompt_len,
            init_temperature=args.init_temperature,
        )
        
        # å¤åˆ¶æƒé‡
        model.encoder.load_state_dict(base_model.encoder.state_dict())
        model.projector.load_state_dict(base_model.projector.state_dict())
        
        if use_lora:
            model.enable_lora(lora_r=args.lora_r, lora_alpha=args.lora_alpha)
        
        del base_model
        torch.cuda.empty_cache()
    
    elif args.local_checkpoint:
        # ä»æœ¬åœ°checkpointåˆ›å»º
        model = OpenTSLMMultiDataset(
            registry=registry,
            llm_id=args.llm_id,
            device=device,
            encoder_type=args.encoder_type,
            prompt_len=args.prompt_len,
            init_temperature=args.init_temperature,
        )
        
        checkpoint = torch.load(args.local_checkpoint, map_location=device, weights_only=False)
        model.encoder.load_state_dict(checkpoint["encoder_state"])
        model.projector.load_state_dict(checkpoint["projector_state"])
        if rank == 0:
            print(f"âœ… åŠ è½½encoder/projector from {args.local_checkpoint}")
        
        if use_lora:
            model.enable_lora(lora_r=args.lora_r, lora_alpha=args.lora_alpha)
            model.load_lora_state_from_checkpoint(checkpoint, allow_missing=True)
    
    else:
        raise ValueError("å¿…é¡»æŒ‡å®š --pretrained_model æˆ– --local_checkpoint")
    
    # ä»resumeåŠ è½½ï¼ˆå¦‚æœæœ‰ï¼‰
    if args.resume_from:
        if rank == 0:
            print(f"ğŸ“‚ ä»{args.resume_from}æ¢å¤...")
        ckpt = torch.load(args.resume_from, map_location=device, weights_only=False)
        model.prompt_bank.load_state_dict(ckpt["prompt_bank_state"])
        model.prototype_bank.load_state_dict(ckpt["prototype_bank_state"])
        model.cls_embed.data = ckpt["cls_embed"].to(device)
        if "cls_projector_state" in ckpt:
            model.cls_projector.load_state_dict(ckpt["cls_projector_state"])
        if rank == 0:
            print(f"âœ… æ¢å¤ PromptBank/PrototypeBank/cls")
    
    # é…ç½®è®­ç»ƒé˜¶æ®µ
    if args.stage == 0:
        model.freeze_backbone()
    else:
        model.unfreeze_for_stage1(unfreeze_encoder=True)
    
    # æ¢¯åº¦æ£€æŸ¥ç‚¹
    if args.gradient_checkpointing:
        model.enable_gradient_checkpointing()
    
    # DDP
    if world_size > 1:
        model = DDP(model, device_ids=[local_rank])
        if rank == 0:
            print(f"âœ… DDP (world_size={world_size})")
    
    # åˆ›å»ºæ•°æ®é›†å’ŒDataLoader
    if rank == 0:
        print("\nğŸ“‚ åˆ›å»ºæ•°æ®åŠ è½½å™¨...")
    
    train_dataset = UnifiedPrototypeDataset(registry, split="train")
    sampler = EpisodicBatchSampler(
        train_dataset,
        batch_size=args.batch_size,
        alpha=args.alpha,
    )
    
    train_loader = DataLoader(
        train_dataset,
        batch_sampler=sampler,
        collate_fn=collate_fn,
    )
    
    if rank == 0:
        print(f"   Train: {len(train_loader)} episodes/epoch")
    
    # ä¼˜åŒ–å™¨
    if rank == 0:
        print("\nâš™ï¸ åˆ›å»ºä¼˜åŒ–å™¨...")
    underlying_model = get_model(model)
    
    param_groups = []
    if args.stage == 0:
        # Stage 0: åªè®­ç»ƒbanks/cls
        param_groups.append({"params": list(underlying_model.prompt_bank.parameters()), "lr": args.lr_prompt_bank})
        param_groups.append({"params": list(underlying_model.prototype_bank.parameters()), "lr": args.lr_prototype_bank})
        param_groups.append({"params": [underlying_model.cls_embed] + list(underlying_model.cls_projector.parameters()), "lr": args.lr_cls})
    else:
        # Stage 1: å…¨éƒ¨è®­ç»ƒ
        param_groups.append({"params": list(underlying_model.encoder.parameters()), "lr": args.lr_encoder})
        param_groups.append({"params": list(underlying_model.projector.parameters()), "lr": args.lr_projector})
        param_groups.append({"params": list(underlying_model.prompt_bank.parameters()), "lr": args.lr_prompt_bank})
        param_groups.append({"params": list(underlying_model.prototype_bank.parameters()), "lr": args.lr_prototype_bank})
        param_groups.append({"params": [underlying_model.cls_embed] + list(underlying_model.cls_projector.parameters()), "lr": args.lr_cls})
        
        if use_lora:
            lora_params = underlying_model.get_lora_parameters()
            if lora_params:
                param_groups.append({"params": lora_params, "lr": args.lr_lora})
    
    optimizer = AdamW(param_groups, weight_decay=args.weight_decay)
    
    # å­¦ä¹ ç‡è°ƒåº¦
    steps_per_epoch = len(train_loader) // args.gradient_accumulation_steps
    total_steps = args.epochs * steps_per_epoch
    warmup_steps = int(args.warmup_ratio * total_steps)
    scheduler = get_linear_schedule_with_warmup(
        optimizer,
        num_warmup_steps=warmup_steps,
        num_training_steps=total_steps,
    )
    
    if rank == 0:
        print(f"   Total steps: {total_steps}")
        print(f"   Warmup steps: {warmup_steps}")
    
    # è®­ç»ƒå¾ªç¯
    if rank == 0:
        print("\nğŸš€ å¼€å§‹è®­ç»ƒ...")
    best_macro_acc = 0.0
    patience_counter = 0
    history = []
    
    try:
        for epoch in range(1, args.epochs + 1):
            train_loss = train_one_epoch(
                model, train_loader, optimizer, scheduler,
                args.grad_clip, epoch, args.epochs,
                args.gradient_accumulation_steps, rank
            )
            
            # è¯„ä¼°
            if epoch % args.eval_every == 0 or epoch == args.epochs:
                if rank == 0:
                    print(f"\nğŸ“Š Epoch {epoch} è¯„ä¼°...")
                
                eval_results = evaluate_multi_dataset(
                    model, registry, split="test",
                    batch_size=args.eval_batch_size, rank=rank
                )
                
                if rank == 0:
                    print(f"   Train Loss: {train_loss:.4f}")
                    print(f"   Macro Avg Acc: {eval_results['macro_avg']:.4f}")
                    print(f"   Worst 10% Acc: {eval_results['worst_10_pct']:.4f}")
                    print(f"   Per-dataset:")
                    for ds_name, ds_result in eval_results["per_dataset"].items():
                        print(f"      {ds_name}: acc={ds_result['accuracy']:.4f}, Ï„={ds_result['temperature']:.3f}")
                
                macro_acc = eval_results["macro_avg"]
                
                if macro_acc > best_macro_acc:
                    best_macro_acc = macro_acc
                    patience_counter = 0
                    save_checkpoint(
                        model, optimizer, scheduler, epoch,
                        macro_acc,
                        os.path.join(save_dir, f"stage{args.stage}_best.pt"),
                        args, rank
                    )
                else:
                    patience_counter += 1
                    if rank == 0:
                        print(f"   (æ— æ”¹è¿›, patience: {patience_counter}/{args.early_stop})")
                
                if rank == 0:
                    history.append({
                        "epoch": epoch,
                        "train_loss": train_loss,
                        "macro_avg": eval_results["macro_avg"],
                        "worst_10_pct": eval_results["worst_10_pct"],
                        "per_dataset": eval_results["per_dataset"],
                    })
                    with open(os.path.join(save_dir, f"history_stage{args.stage}.json"), "w") as f:
                        json.dump(history, f, indent=2)
            else:
                if rank == 0:
                    print(f"Epoch {epoch}: Train Loss = {train_loss:.4f}")
            
            if patience_counter >= args.early_stop:
                if rank == 0:
                    print(f"\nâ¹ï¸ æ—©åœ!")
                break
        
        # æœ€ç»ˆç»“æœ
        if rank == 0:
            print("\n" + "=" * 60)
            print("ğŸ“‹ æœ€ç»ˆç»“æœ")
            print(f"   Best Macro Avg Acc: {best_macro_acc:.4f}")
            
            final_results = {
                "stage": args.stage,
                "best_macro_acc": best_macro_acc,
                "epochs_trained": epoch,
                "config": vars(args),
            }
            
            with open(os.path.join(save_dir, f"final_results_stage{args.stage}.json"), "w") as f:
                json.dump(final_results, f, indent=2)
            
            print("=" * 60)
            print(f"ç»“æœä¿å­˜åˆ°: {save_dir}")
    
    finally:
        cleanup_distributed()


if __name__ == "__main__":
    main()
